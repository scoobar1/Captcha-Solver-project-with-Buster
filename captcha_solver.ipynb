{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1bcfc1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Computer Vision\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mskimage\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m local_binary_pattern, hog\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mskimage\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmeasure\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m regionprops\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ndimage, stats\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1412\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\all data\\New folder\\.venv\\Lib\\site-packages\\lazy_loader\\__init__.py:82\u001b[39m, in \u001b[36mattach.<locals>.__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attr_to_modules:\n\u001b[32m     81\u001b[39m     submod_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     submod = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     attr = \u001b[38;5;28mgetattr\u001b[39m(submod, name)\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     86\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\all data\\New folder\\.venv\\Lib\\site-packages\\skimage\\feature\\_hog.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _hoghistogram\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_shared\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_hog_normalize_block\u001b[39m(block, method, eps=\u001b[32m1e-5\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:645\u001b[39m, in \u001b[36mparent\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import mss\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pyautogui\n",
    "import json\n",
    "import os\n",
    "import hashlib\n",
    "import asyncio\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple, Optional, Union\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import gc\n",
    "import psutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Computer Vision\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "from skimage.measure import regionprops\n",
    "from scipy import ndimage, stats\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Security & Config\n",
    "import configparser\n",
    "import secrets\n",
    "from cryptography.fernet import Fernet\n",
    "import tempfile\n",
    "\n",
    "# Advanced Statistics\n",
    "try:\n",
    "    from statsmodels.stats.proportion import proportion_confint\n",
    "    from statsmodels.stats.contingency_tables import mcnemar\n",
    "    HAS_STATSMODELS = True\n",
    "    print(\"✅ statsmodels متاحة - سيتم استخدام إحصائيات متقدمة\")\n",
    "except ImportError:\n",
    "    HAS_STATSMODELS = False\n",
    "    print(\"⚠️ statsmodels غير مثبتة - سيتم استخدام إحصائيات بسيطة\")\n",
    "\n",
    "# ================================\n",
    "# Advanced Statistics Helper\n",
    "# ================================\n",
    "\n",
    "def calculate_confidence_interval(scores, confidence=0.95):\n",
    "    \"\"\"حساب فترة الثقة للنتائج مع دعم statsmodels\"\"\"\n",
    "    try:\n",
    "        if len(scores) < 2:\n",
    "            return np.mean(scores) if scores else 0, 0, 0\n",
    "        \n",
    "        mean_score = np.mean(scores)\n",
    "        \n",
    "        if HAS_STATSMODELS and len(scores) > 5:\n",
    "            # استخدام statsmodels للحسابات المتقدمة\n",
    "            std_err = stats.sem(scores)\n",
    "            h = std_err * stats.t.ppf((1 + confidence) / 2., len(scores)-1)\n",
    "            return mean_score, mean_score - h, mean_score + h\n",
    "        else:\n",
    "            # حساب بسيط\n",
    "            std_err = stats.sem(scores)\n",
    "            h = std_err * stats.t.ppf((1 + confidence) / 2., len(scores)-1)\n",
    "            return mean_score, mean_score - h, mean_score + h\n",
    "            \n",
    "    except Exception as e:\n",
    "        return np.mean(scores) if scores else 0, 0, 0\n",
    "\n",
    "def calculate_accuracy_confidence_interval(y_true, y_pred, confidence=0.95):\n",
    "    \"\"\"حساب فترة الثقة لدقة النموذج\"\"\"\n",
    "    try:\n",
    "        if HAS_STATSMODELS:\n",
    "            correct = np.sum(y_true == y_pred)\n",
    "            total = len(y_true)\n",
    "            ci_low, ci_upp = proportion_confint(correct, total, alpha=1-confidence)\n",
    "            return accuracy_score(y_true, y_pred), ci_low, ci_upp\n",
    "        else:\n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "            return accuracy, max(0, accuracy - 0.1), min(1, accuracy + 0.1)\n",
    "    except:\n",
    "        return 0, 0, 0\n",
    "\n",
    "# ================================\n",
    "# Configuration & Security Layer\n",
    "# ================================\n",
    "\n",
    "@dataclass\n",
    "class SecurityConfig:\n",
    "    \"\"\"إعدادات الأمان المتقدمة\"\"\"\n",
    "    max_memory_usage_mb: int = 1024\n",
    "    max_cpu_usage_percent: float = 80.0\n",
    "    encryption_enabled: bool = True\n",
    "    secure_temp_dir: bool = True\n",
    "    max_file_size_mb: int = 100\n",
    "    allowed_extensions: List[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.allowed_extensions is None:\n",
    "            self.allowed_extensions = ['.png', '.jpg', '.jpeg', '.json', '.pkl']\n",
    "\n",
    "@dataclass\n",
    "class PerformanceConfig:\n",
    "    \"\"\"إعدادات الأداء المحسنة\"\"\"\n",
    "    frame_buffer_size: int = 3\n",
    "    roi_update_interval: float = 1.0\n",
    "    memory_cleanup_interval: float = 30.0\n",
    "    max_screenshot_resolution: Tuple[int, int] = (1920, 1080)\n",
    "    adaptive_quality: bool = True\n",
    "    parallel_processing: bool = True\n",
    "    max_workers: int = 4\n",
    "\n",
    "@dataclass\n",
    "class LearningConfig:\n",
    "    \"\"\"إعدادات التعلم التكيفي\"\"\"\n",
    "    min_samples_for_learning: int = 10\n",
    "    learning_rate: float = 0.1\n",
    "    adaptation_speed: float = 0.05\n",
    "    pattern_memory_size: int = 100\n",
    "    success_weight: float = 1.0\n",
    "    failure_weight: float = 0.5\n",
    "    time_decay_factor: float = 0.95\n",
    "\n",
    "class SecureConfigManager:\n",
    "    \"\"\"مدير الإعدادات الآمن\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str = \"config/captcha_config.ini\"):\n",
    "        self.config_path = Path(config_path)\n",
    "        self.config_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        self.config = configparser.ConfigParser()\n",
    "        self.encryption_key = self._get_or_create_key()\n",
    "        self.cipher = Fernet(self.encryption_key)\n",
    "        self._load_config()\n",
    "    \n",
    "    def _get_or_create_key(self) -> bytes:\n",
    "        \"\"\"إنشاء أو تحميل مفتاح التشفير\"\"\"\n",
    "        key_file = self.config_path.parent / \".key\"\n",
    "        try:\n",
    "            if key_file.exists():\n",
    "                return key_file.read_bytes()\n",
    "            else:\n",
    "                key = Fernet.generate_key()\n",
    "                key_file.write_bytes(key)\n",
    "                key_file.chmod(0o600)\n",
    "                return key\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"فشل في إدارة مفتاح التشفير: {e}\")\n",
    "            return Fernet.generate_key()\n",
    "    \n",
    "    def _load_config(self):\n",
    "        \"\"\"تحميل الإعدادات\"\"\"\n",
    "        try:\n",
    "            if self.config_path.exists():\n",
    "                self.config.read(self.config_path)\n",
    "            else:\n",
    "                self._create_default_config()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في تحميل الإعدادات: {e}\")\n",
    "            self._create_default_config()\n",
    "    \n",
    "    def _create_default_config(self):\n",
    "        \"\"\"إنشاء إعدادات افتراضية\"\"\"\n",
    "        self.config['PATHS'] = {\n",
    "            'templates_dir': 'templates',\n",
    "            'memory_dir': 'captcha_memory',\n",
    "            'logs_dir': 'logs',\n",
    "            'temp_dir': 'temp'\n",
    "        }\n",
    "        \n",
    "        self.config['SECURITY'] = {\n",
    "            'max_memory_mb': '1024',\n",
    "            'max_cpu_percent': '80.0',\n",
    "            'encryption_enabled': 'true',\n",
    "            'secure_temp': 'true'\n",
    "        }\n",
    "        \n",
    "        self.config['PERFORMANCE'] = {\n",
    "            'frame_buffer_size': '3',\n",
    "            'roi_update_interval': '1.0',\n",
    "            'memory_cleanup_interval': '30.0',\n",
    "            'parallel_processing': 'true',\n",
    "            'max_workers': '4'\n",
    "        }\n",
    "        \n",
    "        self.config['ML'] = {\n",
    "            'model_retrain_interval': '600',\n",
    "            'min_training_samples': '50',\n",
    "            'feature_selection_k': '15',\n",
    "            'cross_validation_folds': '5'\n",
    "        }\n",
    "        \n",
    "        self.config['LEARNING'] = {\n",
    "            'min_samples_for_learning': '10',\n",
    "            'learning_rate': '0.1',\n",
    "            'adaptation_speed': '0.05',\n",
    "            'pattern_memory_size': '100',\n",
    "            'auto_save_interval': '300'\n",
    "        }\n",
    "        \n",
    "        self.save_config()\n",
    "    \n",
    "    def save_config(self):\n",
    "        \"\"\"حفظ الإعدادات\"\"\"\n",
    "        try:\n",
    "            with open(self.config_path, 'w') as f:\n",
    "                self.config.write(f)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في حفظ الإعدادات: {e}\")\n",
    "    \n",
    "    def get_template_path(self, template_name: str) -> Path:\n",
    "        \"\"\"الحصول على مسار آمن للقالب\"\"\"\n",
    "        templates_dir = Path(self.config.get('PATHS', 'templates_dir', fallback='templates'))\n",
    "        templates_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        safe_name = \"\".join(c for c in template_name if c.isalnum() or c in \"._-\")\n",
    "        return templates_dir / f\"{safe_name}.png\"\n",
    "    \n",
    "    def get_secure_path(self, section: str, key: str, filename: str = \"\") -> Path:\n",
    "        \"\"\"الحصول على مسار آمن\"\"\"\n",
    "        base_dir = Path(self.config.get('PATHS', key, fallback=key))\n",
    "        base_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        if filename:\n",
    "            safe_filename = \"\".join(c for c in filename if c.isalnum() or c in \"._-\")\n",
    "            return base_dir / safe_filename\n",
    "        return base_dir\n",
    "\n",
    "# ================================\n",
    "# Advanced Performance Monitor\n",
    "# ================================\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    \"\"\"مراقب الأداء المتقدم\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PerformanceConfig):\n",
    "        self.config = config\n",
    "        self.process = psutil.Process()\n",
    "        self.memory_history = deque(maxlen=100)\n",
    "        self.cpu_history = deque(maxlen=100)\n",
    "        self.last_cleanup = time.time()\n",
    "        self.performance_alerts = []\n",
    "        \n",
    "    def check_resources(self) -> Dict[str, Union[bool, float]]:\n",
    "        \"\"\"فحص الموارد المتاحة\"\"\"\n",
    "        try:\n",
    "            memory_mb = self.process.memory_info().rss / 1024 / 1024\n",
    "            cpu_percent = self.process.cpu_percent()\n",
    "            \n",
    "            self.memory_history.append(memory_mb)\n",
    "            self.cpu_history.append(cpu_percent)\n",
    "            \n",
    "            return {\n",
    "                'memory_ok': memory_mb < self.config.max_memory_usage_mb,\n",
    "                'cpu_ok': cpu_percent < self.config.max_cpu_usage_percent,\n",
    "                'memory_mb': memory_mb,\n",
    "                'cpu_percent': cpu_percent,\n",
    "                'memory_trend': self._calculate_trend(self.memory_history),\n",
    "                'cpu_trend': self._calculate_trend(self.cpu_history)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في فحص الموارد: {e}\")\n",
    "            return {'memory_ok': True, 'cpu_ok': True, 'memory_mb': 0, 'cpu_percent': 0}\n",
    "    \n",
    "    def _calculate_trend(self, history: deque) -> str:\n",
    "        \"\"\"حساب اتجاه الاستخدام\"\"\"\n",
    "        if len(history) < 5:\n",
    "            return \"stable\"\n",
    "        \n",
    "        recent = list(history)[-5:]\n",
    "        older = list(history)[-10:-5] if len(history) >= 10 else recent\n",
    "        \n",
    "        recent_avg = np.mean(recent)\n",
    "        older_avg = np.mean(older)\n",
    "        \n",
    "        if recent_avg > older_avg * 1.2:\n",
    "            return \"increasing\"\n",
    "        elif recent_avg < older_avg * 0.8:\n",
    "            return \"decreasing\"\n",
    "        return \"stable\"\n",
    "    \n",
    "    def should_cleanup(self) -> bool:\n",
    "        \"\"\"تحديد ما إذا كان يجب تنظيف الذاكرة\"\"\"\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_cleanup > self.config.memory_cleanup_interval:\n",
    "            self.last_cleanup = current_time\n",
    "            return True\n",
    "        \n",
    "        resources = self.check_resources()\n",
    "        return not resources['memory_ok'] or resources['memory_trend'] == 'increasing'\n",
    "    \n",
    "    def cleanup_memory(self):\n",
    "        \"\"\"تنظيف الذاكرة\"\"\"\n",
    "        try:\n",
    "            gc.collect()\n",
    "            logging.info(\"تم تنظيف الذاكرة\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في تنظيف الذاكرة: {e}\")\n",
    "\n",
    "# ================================\n",
    "# Adaptive Learning Engine\n",
    "# ================================\n",
    "\n",
    "class AdaptiveLearningEngine:\n",
    "    \"\"\"محرك التعلم التكيفي المتقدم\"\"\"\n",
    "    \n",
    "    def __init__(self, config: LearningConfig, config_manager: SecureConfigManager):\n",
    "        self.config = config\n",
    "        self.config_manager = config_manager\n",
    "        \n",
    "        # بيانات التعلم\n",
    "        self.timing_patterns = {\n",
    "            'verified_wait': deque(maxlen=config.pattern_memory_size),\n",
    "            'success_wait': deque(maxlen=config.pattern_memory_size),\n",
    "            'click_delays': deque(maxlen=config.pattern_memory_size)\n",
    "        }\n",
    "        \n",
    "        self.success_patterns = {\n",
    "            'click_positions': deque(maxlen=config.pattern_memory_size),\n",
    "            'timing_sequences': deque(maxlen=config.pattern_memory_size),\n",
    "            'context_patterns': deque(maxlen=config.pattern_memory_size)\n",
    "        }\n",
    "        \n",
    "        self.adaptive_parameters = {\n",
    "            'verified_timeout': 15.0,\n",
    "            'success_timeout': 20.0,\n",
    "            'click_delay': 0.3,\n",
    "            'check_interval': 0.2,\n",
    "            'confidence_threshold': 0.7\n",
    "        }\n",
    "        \n",
    "        self.learning_stats = {\n",
    "            'total_samples': 0,\n",
    "            'successful_adaptations': 0,\n",
    "            'failed_adaptations': 0,\n",
    "            'last_adaptation': None,\n",
    "            'adaptation_history': deque(maxlen=50)\n",
    "        }\n",
    "        \n",
    "        self._load_learning_data()\n",
    "    \n",
    "    def _load_learning_data(self):\n",
    "        \"\"\"تحميل بيانات التعلم المحفوظة\"\"\"\n",
    "        try:\n",
    "            learning_file = self.config_manager.get_secure_path('PATHS', 'memory_dir', 'adaptive_learning.json')\n",
    "            \n",
    "            if learning_file.exists():\n",
    "                with open(learning_file, 'r', encoding='utf-8') as f:\n",
    "                    saved_data = json.load(f)\n",
    "                \n",
    "                # استعادة المعاملات التكيفية\n",
    "                if 'adaptive_parameters' in saved_data:\n",
    "                    self.adaptive_parameters.update(saved_data['adaptive_parameters'])\n",
    "                \n",
    "                # استعادة الإحصائيات\n",
    "                if 'learning_stats' in saved_data:\n",
    "                    self.learning_stats.update(saved_data['learning_stats'])\n",
    "                    # تحويل التاريخ إلى deque\n",
    "                    if 'adaptation_history' in saved_data['learning_stats']:\n",
    "                        self.learning_stats['adaptation_history'] = deque(\n",
    "                            saved_data['learning_stats']['adaptation_history'],\n",
    "                            maxlen=50\n",
    "                        )\n",
    "                \n",
    "                # استعادة الأنماط (الأحدث فقط)\n",
    "                if 'timing_patterns' in saved_data:\n",
    "                    for key, values in saved_data['timing_patterns'].items():\n",
    "                        if key in self.timing_patterns:\n",
    "                         self.timing_patterns[key] = deque(values[-self.config.pattern_memory_size:], \n",
    "                         maxlen=self.config.pattern_memory_size)\n",
    "                \n",
    "                if 'success_patterns' in saved_data:\n",
    "                    for key, values in saved_data['success_patterns'].items():\n",
    "                        if key in self.success_patterns:\n",
    "                            self.success_patterns[key] = deque(values[-self.config.pattern_memory_size:], \n",
    "                                                             maxlen=self.config.pattern_memory_size)\n",
    "                \n",
    "                logging.info(f\"تم تحميل بيانات التعلم: {self.learning_stats['total_samples']} عينة\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في تحميل بيانات التعلم: {e}\")\n",
    "    \n",
    "    def _save_learning_data(self):\n",
    "        \"\"\"حفظ بيانات التعلم\"\"\"\n",
    "        try:\n",
    "            learning_file = self.config_manager.get_secure_path('PATHS', 'memory_dir', 'adaptive_learning.json')\n",
    "            \n",
    "            save_data = {\n",
    "                'adaptive_parameters': self.adaptive_parameters.copy(),\n",
    "                'learning_stats': {\n",
    "                    'total_samples': self.learning_stats['total_samples'],\n",
    "                    'successful_adaptations': self.learning_stats['successful_adaptations'],\n",
    "                    'failed_adaptations': self.learning_stats['failed_adaptations'],\n",
    "                    'last_adaptation': self.learning_stats['last_adaptation'],\n",
    "                    'adaptation_history': list(self.learning_stats['adaptation_history'])\n",
    "                },\n",
    "                'timing_patterns': {\n",
    "                    key: list(values) for key, values in self.timing_patterns.items()\n",
    "                },\n",
    "                'success_patterns': {\n",
    "                    key: list(values) for key, values in self.success_patterns.items()\n",
    "                },\n",
    "                'save_timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            with open(learning_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(save_data, f, indent=2, ensure_ascii=False)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في حفظ بيانات التعلم: {e}\")\n",
    "    \n",
    "    def learn_from_timing(self, event_type: str, duration: float, success: bool, context: Dict = None):\n",
    "        \"\"\"التعلم من أوقات الأحداث\"\"\"\n",
    "        try:\n",
    "            current_time = time.time()\n",
    "            \n",
    "            # تسجيل التوقيت\n",
    "            timing_record = {\n",
    "                'duration': duration,\n",
    "                'success': success,\n",
    "                'timestamp': current_time,\n",
    "                'context': context or {}\n",
    "            }\n",
    "            \n",
    "            if event_type in self.timing_patterns:\n",
    "                self.timing_patterns[event_type].append(timing_record)\n",
    "            \n",
    "            # تحديث المعاملات التكيفية\n",
    "            if success:\n",
    "                self._adapt_timing_parameters(event_type, duration, True)\n",
    "                self.learning_stats['successful_adaptations'] += 1\n",
    "            else:\n",
    "                self._adapt_timing_parameters(event_type, duration, False)\n",
    "                self.learning_stats['failed_adaptations'] += 1\n",
    "            \n",
    "            self.learning_stats['total_samples'] += 1\n",
    "            self.learning_stats['last_adaptation'] = current_time\n",
    "            \n",
    "            # حفظ تاريخ التكيف\n",
    "            adaptation_record = {\n",
    "                'timestamp': current_time,\n",
    "                'event_type': event_type,\n",
    "                'duration': duration,\n",
    "                'success': success,\n",
    "                'parameters_before': self.adaptive_parameters.copy()\n",
    "            }\n",
    "            \n",
    "            self.learning_stats['adaptation_history'].append(adaptation_record)\n",
    "            \n",
    "            logging.debug(f\"تعلم من {event_type}: {duration:.2f}s، نجاح: {success}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في التعلم من التوقيت: {e}\")\n",
    "    \n",
    "    def _adapt_timing_parameters(self, event_type: str, duration: float, success: bool):\n",
    "        \"\"\"تكييف معاملات التوقيت بناءً على النتائج\"\"\"\n",
    "        try:\n",
    "            adaptation_rate = self.config.adaptation_speed\n",
    "            \n",
    "            if event_type == 'verified_wait':\n",
    "                current_timeout = self.adaptive_parameters['verified_timeout']\n",
    "                \n",
    "                if success:\n",
    "                    # إذا نجح في وقت أقل من المهلة، قلل المهلة تدريجياً\n",
    "                    if duration < current_timeout * 0.8:\n",
    "                        new_timeout = current_timeout * (1 - adaptation_rate)\n",
    "                        self.adaptive_parameters['verified_timeout'] = max(5.0, new_timeout)\n",
    "                else:\n",
    "                    # إذا فشل، زد المهلة\n",
    "                    new_timeout = current_timeout * (1 + adaptation_rate)\n",
    "                    self.adaptive_parameters['verified_timeout'] = min(30.0, new_timeout)\n",
    "            \n",
    "            elif event_type == 'success_wait':\n",
    "                current_timeout = self.adaptive_parameters['success_timeout']\n",
    "                \n",
    "                if success:\n",
    "                    if duration < current_timeout * 0.8:\n",
    "                        new_timeout = current_timeout * (1 - adaptation_rate)\n",
    "                        self.adaptive_parameters['success_timeout'] = max(8.0, new_timeout)\n",
    "                else:\n",
    "                    new_timeout = current_timeout * (1 + adaptation_rate)\n",
    "                    self.adaptive_parameters['success_timeout'] = min(40.0, new_timeout)\n",
    "            \n",
    "            elif event_type == 'click_delays':\n",
    "                current_delay = self.adaptive_parameters['click_delay']\n",
    "                \n",
    "                if success:\n",
    "                    # تسريع النقر تدريجياً عند النجاح\n",
    "                    new_delay = current_delay * (1 - adaptation_rate * 0.5)\n",
    "                    self.adaptive_parameters['click_delay'] = max(0.1, new_delay)\n",
    "                else:\n",
    "                    # إبطاء النقر عند الفشل\n",
    "                    new_delay = current_delay * (1 + adaptation_rate)\n",
    "                    self.adaptive_parameters['click_delay'] = min(2.0, new_delay)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في تكييف المعاملات: {e}\")\n",
    "    \n",
    "    def learn_from_click_pattern(self, click_position: Tuple[int, int], element_type: str, \n",
    "                               success: bool, confidence: float, context: Dict = None):\n",
    "        \"\"\"التعلم من أنماط النقر\"\"\"\n",
    "        try:\n",
    "            current_time = time.time()\n",
    "            \n",
    "            click_record = {\n",
    "                'position': click_position,\n",
    "                'element_type': element_type,\n",
    "                'success': success,\n",
    "                'confidence': confidence,\n",
    "                'timestamp': current_time,\n",
    "                'context': context or {}\n",
    "            }\n",
    "            \n",
    "            self.success_patterns['click_positions'].append(click_record)\n",
    "            \n",
    "            # تحديث عتبة الثقة بناءً على النجاح\n",
    "            if success and confidence > self.adaptive_parameters['confidence_threshold']:\n",
    "                # زيادة عتبة الثقة تدريجياً للحصول على دقة أفضل\n",
    "                current_threshold = self.adaptive_parameters['confidence_threshold']\n",
    "                new_threshold = current_threshold + (confidence - current_threshold) * self.config.adaptation_speed\n",
    "                self.adaptive_parameters['confidence_threshold'] = min(0.95, new_threshold)\n",
    "            \n",
    "            elif not success:\n",
    "                # تقليل عتبة الثقة عند الفشل\n",
    "                current_threshold = self.adaptive_parameters['confidence_threshold']\n",
    "                new_threshold = current_threshold * (1 - self.config.adaptation_speed)\n",
    "                self.adaptive_parameters['confidence_threshold'] = max(0.5, new_threshold)\n",
    "            \n",
    "            logging.debug(f\"تعلم من نقر {element_type}: موقع {click_position}، نجاح: {success}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في التعلم من نمط النقر: {e}\")\n",
    "    \n",
    "    def get_optimal_timeout(self, event_type: str) -> float:\n",
    "        \"\"\"الحصول على المهلة المثلى لنوع حدث معين\"\"\"\n",
    "        try:\n",
    "            if event_type == 'verified':\n",
    "                return self.adaptive_parameters['verified_timeout']\n",
    "            elif event_type == 'success':\n",
    "                return self.adaptive_parameters['success_timeout']\n",
    "            else:\n",
    "                return self.adaptive_parameters.get(f'{event_type}_timeout', 10.0)\n",
    "        except:\n",
    "            return 10.0\n",
    "    \n",
    "    def get_optimal_click_delay(self, element_type: str = None) -> float:\n",
    "        \"\"\"الحصول على تأخير النقر الأمثل\"\"\"\n",
    "        try:\n",
    "            base_delay = self.adaptive_parameters['click_delay']\n",
    "            \n",
    "            # تعديل بناءً على نوع العنصر\n",
    "            if element_type == 'recaptcha':\n",
    "                return base_delay * 1.2  # تأخير أطول للكابتشا\n",
    "            elif element_type in ['verified', 'done', 'google']:\n",
    "                return base_delay * 0.8  # تأخير أقل للعناصر السريعة\n",
    "            \n",
    "            return base_delay\n",
    "        except:\n",
    "            return 0.3\n",
    "    \n",
    "    def get_optimal_confidence_threshold(self, element_type: str = None) -> float:\n",
    "        \"\"\"الحصول على عتبة الثقة المثلى\"\"\"\n",
    "        try:\n",
    "            base_threshold = self.adaptive_parameters['confidence_threshold']\n",
    "            \n",
    "            # تعديل بناءً على نوع العنصر\n",
    "            if element_type == 'recaptcha':\n",
    "                return max(0.6, base_threshold - 0.1)  # عتبة أقل للكابتشا\n",
    "            elif element_type in ['verified', 'done', 'google']:\n",
    "                return min(0.9, base_threshold + 0.1)  # عتبة أعلى للعناصر الواضحة\n",
    "            \n",
    "            return base_threshold\n",
    "        except:\n",
    "            return 0.7\n",
    "    \n",
    "    def predict_optimal_click_position(self, element_type: str, detected_position: Tuple[int, int], \n",
    "                                     confidence: float) -> Tuple[int, int]:\n",
    "        \"\"\"التنبؤ بموقع النقر الأمثل بناءً على التعلم\"\"\"\n",
    "        try:\n",
    "            # البحث عن أنماط ناجحة مشابهة\n",
    "            successful_clicks = [\n",
    "                record for record in self.success_patterns['click_positions']\n",
    "                if record['element_type'] == element_type and record['success'] and \n",
    "                record['confidence'] >= confidence * 0.9\n",
    "            ]\n",
    "            \n",
    "            if len(successful_clicks) >= self.config.min_samples_for_learning:\n",
    "                # حساب متوسط الإزاحة من المواقع الناجحة\n",
    "                base_x, base_y = detected_position\n",
    "                \n",
    "                offsets_x = []\n",
    "                offsets_y = []\n",
    "                weights = []\n",
    "                \n",
    "                for record in successful_clicks[-20:]:  # آخر 20 نقرة ناجحة\n",
    "                    record_x, record_y = record['position']\n",
    "                    \n",
    "                    # حساب الوزن بناءً على الوقت والثقة\n",
    "                    time_weight = self.config.time_decay_factor ** (\n",
    "                        (time.time() - record['timestamp']) / 86400  # تقليل الوزن مع الوقت\n",
    "                    )\n",
    "                    confidence_weight = record['confidence']\n",
    "                    total_weight = time_weight * confidence_weight\n",
    "                    \n",
    "                    # حساب الإزاحة النسبية (افتراض أن الكشف الحالي مرجع)\n",
    "                    offset_x = record_x - base_x\n",
    "                    offset_y = record_y - base_y\n",
    "                    \n",
    "                    offsets_x.append(offset_x)\n",
    "                    offsets_y.append(offset_y)\n",
    "                    weights.append(total_weight)\n",
    "                \n",
    "                if weights:\n",
    "                    # حساب متوسط مرجح للإزاحة\n",
    "                    avg_offset_x = np.average(offsets_x, weights=weights)\n",
    "                    avg_offset_y = np.average(offsets_y, weights=weights)\n",
    "                    \n",
    "                    # تطبيق الإزاحة المتعلمة\n",
    "                    optimized_x = int(base_x + avg_offset_x)\n",
    "                    optimized_y = int(base_y + avg_offset_y)\n",
    "                    \n",
    "                    # التأكد من أن الموقع معقول (ضمن نطاق محدود)\n",
    "                    max_offset = 50\n",
    "                    optimized_x = max(base_x - max_offset, min(base_x + max_offset, optimized_x))\n",
    "                    optimized_y = max(base_y - max_offset, min(base_y + max_offset, optimized_y))\n",
    "                    \n",
    "                    logging.debug(f\"موقع محسن لـ {element_type}: ({optimized_x}, {optimized_y}) \"\n",
    "                                f\"إزاحة: ({avg_offset_x:.1f}, {avg_offset_y:.1f})\")\n",
    "                    \n",
    "                    return (optimized_x, optimized_y)\n",
    "            \n",
    "            # إذا لم توجد بيانات كافية، استخدم الموقع المكتشف مع تشويش صغير\n",
    "            noise_x = np.random.randint(-3, 4)\n",
    "            noise_y = np.random.randint(-3, 4)\n",
    "            return (detected_position[0] + noise_x, detected_position[1] + noise_y)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في التنبؤ بموقع النقر: {e}\")\n",
    "            return detected_position\n",
    "    \n",
    "    def get_learning_statistics(self) -> Dict:\n",
    "        \"\"\"الحصول على إحصائيات التعلم\"\"\"\n",
    "        try:\n",
    "            stats = {\n",
    "                'total_samples': self.learning_stats['total_samples'],\n",
    "                'successful_adaptations': self.learning_stats['successful_adaptations'],\n",
    "                'failed_adaptations': self.learning_stats['failed_adaptations'],\n",
    "                'adaptation_rate': 0.0,\n",
    "                'current_parameters': self.adaptive_parameters.copy(),\n",
    "                'pattern_counts': {\n",
    "                    key: len(values) for key, values in self.timing_patterns.items()\n",
    "                },\n",
    "                'success_pattern_counts': {\n",
    "                    key: len(values) for key, values in self.success_patterns.items()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            total_adaptations = stats['successful_adaptations'] + stats['failed_adaptations']\n",
    "            if total_adaptations > 0:\n",
    "                stats['adaptation_rate'] = stats['successful_adaptations'] / total_adaptations\n",
    "            \n",
    "            # إحصائيات الأوقات\n",
    "            if self.timing_patterns['verified_wait']:\n",
    "                recent_verified = list(self.timing_patterns['verified_wait'])[-10:]\n",
    "                successful_verified = [r for r in recent_verified if r['success']]\n",
    "                if successful_verified:\n",
    "                    stats['avg_verified_time'] = np.mean([r['duration'] for r in successful_verified])\n",
    "            \n",
    "            if self.timing_patterns['success_wait']:\n",
    "                recent_success = list(self.timing_patterns['success_wait'])[-10:]\n",
    "                successful_success = [r for r in recent_success if r['success']]\n",
    "                if successful_success:\n",
    "                    stats['avg_success_time'] = np.mean([r['duration'] for r in successful_success])\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في حساب إحصائيات التعلم: {e}\")\n",
    "            return {'total_samples': 0, 'adaptation_rate': 0.0}\n",
    "    \n",
    "    def should_save_learning_data(self) -> bool:\n",
    "        \"\"\"تحديد ما إذا كان يجب حفظ بيانات التعلم\"\"\"\n",
    "        try:\n",
    "            auto_save_interval = int(self.config_manager.config.get('LEARNING', 'auto_save_interval', fallback='300'))\n",
    "            \n",
    "            if self.learning_stats['last_adaptation'] is None:\n",
    "                return False\n",
    "            \n",
    "            time_since_last_save = time.time() - self.learning_stats.get('last_save', 0)\n",
    "            return time_since_last_save > auto_save_interval\n",
    "            \n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def auto_save_if_needed(self):\n",
    "        \"\"\"حفظ تلقائي إذا لزم الأمر\"\"\"\n",
    "        try:\n",
    "            if self.should_save_learning_data():\n",
    "                self._save_learning_data()\n",
    "                self.learning_stats['last_save'] = time.time()\n",
    "                logging.info(\"تم الحفظ التلقائي لبيانات التعلم\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في الحفظ التلقائي: {e}\")\n",
    "\n",
    "# ================================\n",
    "# Advanced Feature Extractor\n",
    "# ================================\n",
    "\n",
    "class AdvancedFeatureExtractor:\n",
    "    \"\"\"مستخرج الميزات المتقدم\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.lbp_radius = 3\n",
    "        self.lbp_n_points = 24\n",
    "        self.hog_orientations = 9\n",
    "        self.hog_pixels_per_cell = (8, 8)\n",
    "        self.hog_cells_per_block = (2, 2)\n",
    "    \n",
    "    def extract_comprehensive_features(self, image: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"استخراج ميزات شاملة ومتقدمة\"\"\"\n",
    "        try:\n",
    "            if len(image.shape) == 3:\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                gray = image.copy()\n",
    "            \n",
    "            features = {}\n",
    "            \n",
    "            # Basic statistical features\n",
    "            features.update(self._extract_statistical_features(gray))\n",
    "            \n",
    "            # Texture features (LBP)\n",
    "            features.update(self._extract_lbp_features(gray))\n",
    "            \n",
    "            # Shape features (HOG)\n",
    "            features.update(self._extract_hog_features(gray))\n",
    "            \n",
    "            # Edge and contour features\n",
    "            features.update(self._extract_edge_features(gray))\n",
    "            \n",
    "            # Color features (if color image)\n",
    "            if len(image.shape) == 3:\n",
    "                features.update(self._extract_color_features(image))\n",
    "            \n",
    "            # Frequency domain features\n",
    "            features.update(self._extract_frequency_features(gray))\n",
    "            \n",
    "            return features\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في استخراج الميزات: {e}\")\n",
    "            return self._get_default_features()\n",
    "    \n",
    "    def _extract_statistical_features(self, gray: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"استخراج الميزات الإحصائية\"\"\"\n",
    "        return {\n",
    "            'mean_intensity': float(np.mean(gray)),\n",
    "            'std_intensity': float(np.std(gray)),\n",
    "            'min_intensity': float(np.min(gray)),\n",
    "            'max_intensity': float(np.max(gray)),\n",
    "            'median_intensity': float(np.median(gray)),\n",
    "            'skewness': float(self._calculate_skewness(gray)),\n",
    "            'kurtosis': float(self._calculate_kurtosis(gray)),\n",
    "            'entropy': float(self._calculate_entropy(gray))\n",
    "        }\n",
    "    \n",
    "    def _extract_lbp_features(self, gray: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"استخراج ميزات Local Binary Pattern\"\"\"\n",
    "        try:\n",
    "            lbp = local_binary_pattern(gray, self.lbp_n_points, self.lbp_radius, method='uniform')\n",
    "            hist, _ = np.histogram(lbp.ravel(), bins=self.lbp_n_points + 2, \n",
    "                                 range=(0, self.lbp_n_points + 2))\n",
    "            hist = hist.astype(float)\n",
    "            hist /= (hist.sum() + 1e-7)\n",
    "            \n",
    "            features = {}\n",
    "            for i, val in enumerate(hist):\n",
    "                features[f'lbp_bin_{i}'] = val\n",
    "            \n",
    "            return features\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في استخراج LBP: {e}\")\n",
    "            return {f'lbp_bin_{i}': 0.0 for i in range(self.lbp_n_points + 2)}\n",
    "    \n",
    "    def _extract_hog_features(self, gray: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"استخراج ميزات Histogram of Oriented Gradients\"\"\"\n",
    "        try:\n",
    "            resized = cv2.resize(gray, (64, 64))\n",
    "            \n",
    "            hog_features = hog(resized, \n",
    "                             orientations=self.hog_orientations,\n",
    "                             pixels_per_cell=self.hog_pixels_per_cell,\n",
    "                             cells_per_block=self.hog_cells_per_block,\n",
    "                             visualize=False)\n",
    "            \n",
    "            important_features = hog_features[:20]\n",
    "            \n",
    "            features = {}\n",
    "            for i, val in enumerate(important_features):\n",
    "                features[f'hog_feature_{i}'] = float(val)\n",
    "            \n",
    "            return features\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في استخراج HOG: {e}\")\n",
    "            return {f'hog_feature_{i}': 0.0 for i in range(20)}\n",
    "    \n",
    "    def _extract_edge_features(self, gray: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"استخراج ميزات الحواف\"\"\"\n",
    "        try:\n",
    "            edges = cv2.Canny(gray, 50, 150)\n",
    "            edge_density = np.sum(edges > 0) / edges.size\n",
    "            \n",
    "            sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "            gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "            \n",
    "            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            return {\n",
    "                'edge_density': float(edge_density),\n",
    "                'gradient_mean': float(np.mean(gradient_magnitude)),\n",
    "                'gradient_std': float(np.std(gradient_magnitude)),\n",
    "                'contour_count': float(len(contours)),\n",
    "                'largest_contour_area': float(cv2.contourArea(max(contours, key=cv2.contourArea)) if contours else 0),\n",
    "                'total_contour_area': float(sum(cv2.contourArea(c) for c in contours))\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في استخراج ميزات الحواف: {e}\")\n",
    "            return {\n",
    "                'edge_density': 0.0,\n",
    "                'gradient_mean': 0.0,\n",
    "                'gradient_std': 0.0,\n",
    "                'contour_count': 0.0,\n",
    "                'largest_contour_area': 0.0,\n",
    "                'total_contour_area': 0.0\n",
    "            }\n",
    "    \n",
    "    def _extract_color_features(self, image: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"استخراج ميزات الألوان\"\"\"\n",
    "        try:\n",
    "            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "            \n",
    "            features = {}\n",
    "            \n",
    "            # BGR channels\n",
    "            for i, channel in enumerate(['b', 'g', 'r']):\n",
    "                features[f'{channel}_mean'] = float(np.mean(image[:, :, i]))\n",
    "                features[f'{channel}_std'] = float(np.std(image[:, :, i]))\n",
    "            \n",
    "            # HSV channels\n",
    "            for i, channel in enumerate(['h', 's', 'v']):\n",
    "                features[f'{channel}_mean'] = float(np.mean(hsv[:, :, i]))\n",
    "                features[f'{channel}_std'] = float(np.std(hsv[:, :, i]))\n",
    "            \n",
    "            # Color histogram\n",
    "            hist_b = cv2.calcHist([image], [0], None, [8], [0, 256])\n",
    "            hist_g = cv2.calcHist([image], [1], None, [8], [0, 256])\n",
    "            hist_r = cv2.calcHist([image], [2], None, [8], [0, 256])\n",
    "            \n",
    "            for i in range(8):\n",
    "                features[f'color_hist_b_{i}'] = float(hist_b[i][0])\n",
    "                features[f'color_hist_g_{i}'] = float(hist_g[i][0])\n",
    "                features[f'color_hist_r_{i}'] = float(hist_r[i][0])\n",
    "            \n",
    "            return features\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في استخراج ميزات الألوان: {e}\")\n",
    "            return {f'color_feature_{i}': 0.0 for i in range(30)}\n",
    "    \n",
    "    def _extract_frequency_features(self, gray: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"استخراج ميزات المجال الترددي\"\"\"\n",
    "        try:\n",
    "            f_transform = np.fft.fft2(gray)\n",
    "            f_shift = np.fft.fftshift(f_transform)\n",
    "            magnitude_spectrum = np.abs(f_shift)\n",
    "            \n",
    "            center = np.array(magnitude_spectrum.shape) // 2\n",
    "            radius = min(center) // 4\n",
    "            \n",
    "            y, x = np.ogrid[:magnitude_spectrum.shape[0], :magnitude_spectrum.shape[1]]\n",
    "            mask = (x - center[1])**2 + (y - center[0])**2 <= radius**2\n",
    "            \n",
    "            low_freq_energy = np.sum(magnitude_spectrum[mask])\n",
    "            high_freq_energy = np.sum(magnitude_spectrum[~mask])\n",
    "            total_energy = low_freq_energy + high_freq_energy\n",
    "            \n",
    "            return {\n",
    "                'low_freq_ratio': float(low_freq_energy / (total_energy + 1e-7)),\n",
    "                'high_freq_ratio': float(high_freq_energy / (total_energy + 1e-7)),\n",
    "                'freq_energy_total': float(total_energy),\n",
    "                'freq_energy_mean': float(np.mean(magnitude_spectrum)),\n",
    "                'freq_energy_std': float(np.std(magnitude_spectrum))\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في استخراج ميزات الترددات: {e}\")\n",
    "            return {\n",
    "                'low_freq_ratio': 0.0,\n",
    "                'high_freq_ratio': 0.0,\n",
    "                'freq_energy_total': 0.0,\n",
    "                'freq_energy_mean': 0.0,\n",
    "                'freq_energy_std': 0.0\n",
    "            }\n",
    "    \n",
    "    def _calculate_skewness(self, data: np.ndarray) -> float:\n",
    "        \"\"\"حساب الانحراف\"\"\"\n",
    "        try:\n",
    "            mean = np.mean(data)\n",
    "            std = np.std(data)\n",
    "            if std == 0:\n",
    "                return 0.0\n",
    "            return np.mean(((data - mean) / std) ** 3)\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def _calculate_kurtosis(self, data: np.ndarray) -> float:\n",
    "        \"\"\"حساب التفلطح\"\"\"\n",
    "        try:\n",
    "            mean = np.mean(data)\n",
    "            std = np.std(data)\n",
    "            if std == 0:\n",
    "                return 0.0\n",
    "            return np.mean(((data - mean) / std) ** 4) - 3\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def _calculate_entropy(self, data: np.ndarray) -> float:\n",
    "        \"\"\"حساب الإنتروبيا\"\"\"\n",
    "        try:\n",
    "            hist, _ = np.histogram(data, bins=256, range=(0, 256))\n",
    "            hist = hist[hist > 0]\n",
    "            prob = hist / np.sum(hist)\n",
    "            return -np.sum(prob * np.log2(prob + 1e-7))\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def _get_default_features(self) -> Dict[str, float]:\n",
    "        \"\"\"ميزات افتراضية في حالة الخطأ\"\"\"\n",
    "        return {f'feature_{i}': 0.0 for i in range(50)}\n",
    "\n",
    "# ================================\n",
    "# Advanced ML Engine\n",
    "# ================================\n",
    "\n",
    "class AdvancedMLEngine:\n",
    "    \"\"\"محرك التعلم الآلي المتقدم\"\"\"\n",
    "    \n",
    "    def __init__(self, config_manager: SecureConfigManager):\n",
    "        self.config_manager = config_manager\n",
    "        self.feature_extractor = AdvancedFeatureExtractor()\n",
    "        \n",
    "        # نماذج متعددة للتنبؤ\n",
    "        self.models = {\n",
    "            'region_classifier': RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            ),\n",
    "            'success_predictor': MLPClassifier(\n",
    "                hidden_layer_sizes=(64, 32, 16),\n",
    "                max_iter=1000,\n",
    "                random_state=42,\n",
    "                early_stopping=True\n",
    "            ),\n",
    "            'click_optimizer': RandomForestClassifier(\n",
    "                n_estimators=50,\n",
    "                max_depth=8,\n",
    "                random_state=42\n",
    "            ),\n",
    "            'anomaly_detector': IsolationForest(\n",
    "                contamination=0.1,\n",
    "                random_state=42\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # معالجات البيانات\n",
    "        self.scalers = {\n",
    "            'standard': StandardScaler(),\n",
    "            'robust': RobustScaler()\n",
    "        }\n",
    "        \n",
    "        self.feature_selector = SelectKBest(\n",
    "            score_func=f_classif,\n",
    "            k=int(self.config_manager.config.get('ML', 'feature_selection_k', fallback='15'))\n",
    "        )\n",
    "        \n",
    "        # إحصائيات النماذج\n",
    "        self.model_stats = {\n",
    "            'training_samples': 0,\n",
    "            'accuracy_scores': {},\n",
    "            'confidence_intervals': {},\n",
    "            'last_training': None,\n",
    "            'feature_importance': {},\n",
    "            'cross_val_scores': {}\n",
    "        }\n",
    "        \n",
    "        self.is_trained = False\n",
    "        self._load_models()\n",
    "    \n",
    "    def _load_models(self):\n",
    "        \"\"\"تحميل النماذج المحفوظة\"\"\"\n",
    "        try:\n",
    "            models_path = self.config_manager.get_secure_path('PATHS', 'memory_dir', 'advanced_models.pkl')\n",
    "            \n",
    "            if models_path.exists():\n",
    "                with open(models_path, 'rb') as f:\n",
    "                    saved_data = pickle.load(f)\n",
    "                    \n",
    "                self.models = saved_data.get('models', self.models)\n",
    "                self.scalers = saved_data.get('scalers', self.scalers)\n",
    "                self.feature_selector = saved_data.get('feature_selector', self.feature_selector)\n",
    "                self.model_stats = saved_data.get('model_stats', self.model_stats)\n",
    "                self.is_trained = saved_data.get('is_trained', False)\n",
    "                \n",
    "                logging.info(\"تم تحميل النماذج المتقدمة بنجاح\")\n",
    "            else:\n",
    "                logging.info(\"لا توجد نماذج محفوظة، سيتم البدء بنماذج جديدة\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في تحميل النماذج: {e}\")\n",
    "            self.is_trained = False\n",
    "    \n",
    "    def _save_models(self):\n",
    "        \"\"\"حفظ النماذج\"\"\"\n",
    "        try:\n",
    "            models_path = self.config_manager.get_secure_path('PATHS', 'memory_dir', 'advanced_models.pkl')\n",
    "            \n",
    "            save_data = {\n",
    "                'models': self.models,\n",
    "                'scalers': self.scalers,\n",
    "                'feature_selector': self.feature_selector,\n",
    "                'model_stats': self.model_stats,\n",
    "                'is_trained': self.is_trained,\n",
    "                'save_timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            with open(models_path, 'wb') as f:\n",
    "                pickle.dump(save_data, f)\n",
    "                \n",
    "            logging.info(\"تم حفظ النماذج المتقدمة\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في حفظ النماذج: {e}\")\n",
    "    \n",
    "    def prepare_training_data(self, training_samples: List[Dict]) -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
    "        \"\"\"إعداد بيانات التدريب المتقدمة\"\"\"\n",
    "        try:\n",
    "            min_samples = int(self.config_manager.config.get('ML', 'min_training_samples', fallback='50'))\n",
    "            if len(training_samples) < min_samples:\n",
    "                raise ValueError(f\"عدد العينات غير كافي: {len(training_samples)}\")\n",
    "            \n",
    "            features_list = []\n",
    "            labels = []\n",
    "            feature_names = []\n",
    "            \n",
    "            for sample in training_samples:\n",
    "                if 'advanced_features' in sample and sample['advanced_features']:\n",
    "                    features_dict = sample['advanced_features']\n",
    "                    \n",
    "                    if not feature_names:\n",
    "                        feature_names = sorted(features_dict.keys())\n",
    "                    \n",
    "                    feature_vector = [features_dict.get(name, 0.0) for name in feature_names]\n",
    "                    features_list.append(feature_vector)\n",
    "                    \n",
    "                    # تحويل النتيجة إلى تصنيف\n",
    "                    result = sample.get('result', 'unknown')\n",
    "                    if result == 'success':\n",
    "                        labels.append(1)\n",
    "                    elif result == 'fail':\n",
    "                        labels.append(0)\n",
    "                    else:\n",
    "                        labels.append(-1)  # غير معروف\n",
    "            \n",
    "            if not features_list:\n",
    "                raise ValueError(\"لا توجد ميزات صالحة للتدريب\")\n",
    "            \n",
    "            X = np.array(features_list)\n",
    "            y = np.array(labels)\n",
    "            \n",
    "            # إزالة العينات غير المعروفة\n",
    "            valid_indices = y != -1\n",
    "            X = X[valid_indices]\n",
    "            y = y[valid_indices]\n",
    "            \n",
    "            if len(X) == 0:\n",
    "                raise ValueError(\"لا توجد عينات صالحة بعد التنظيف\")\n",
    "            \n",
    "            # معالجة القيم المفقودة\n",
    "            X = np.nan_to_num(X, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "            \n",
    "            return X, y, feature_names\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في إعداد بيانات التدريب: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def train_models(self, training_samples: List[Dict]) -> Dict[str, float]:\n",
    "        \"\"\"تدريب النماذج المتقدمة مع إحصائيات متقدمة\"\"\"\n",
    "        try:\n",
    "            logging.info(f\"بدء تدريب النماذج على {len(training_samples)} عينة\")\n",
    "            \n",
    "            X, y, feature_names = self.prepare_training_data(training_samples)\n",
    "            \n",
    "            # تطبيع البيانات\n",
    "            X_scaled = self.scalers['robust'].fit_transform(X)\n",
    "            \n",
    "            # اختيار الميزات المهمة\n",
    "            k_features = int(self.config_manager.config.get('ML', 'feature_selection_k', fallback='15'))\n",
    "            if len(feature_names) > k_features:\n",
    "                X_selected = self.feature_selector.fit_transform(X_scaled, y)\n",
    "                selected_features = self.feature_selector.get_support()\n",
    "                logging.info(f\"تم اختيار {np.sum(selected_features)} ميزة من {len(feature_names)}\")\n",
    "            else:\n",
    "                X_selected = X_scaled\n",
    "            \n",
    "            # تدريب النماذج\n",
    "            results = {}\n",
    "            confidence_intervals = {}\n",
    "            \n",
    "            # تدريب مصنف المناطق\n",
    "            if len(np.unique(y)) > 1:\n",
    "                self.models['region_classifier'].fit(X_selected, y)\n",
    "                \n",
    "                # تقييم متقاطع مع فترات الثقة\n",
    "                cv_folds = int(self.config_manager.config.get('ML', 'cross_validation_folds', fallback='5'))\n",
    "                cv_scores = cross_val_score(self.models['region_classifier'], X_selected, y, cv=cv_folds)\n",
    "                \n",
    "                mean_score, ci_low, ci_high = calculate_confidence_interval(cv_scores)\n",
    "                results['region_classifier'] = mean_score\n",
    "                confidence_intervals['region_classifier'] = (ci_low, ci_high)\n",
    "                self.model_stats['cross_val_scores']['region_classifier'] = cv_scores.tolist()\n",
    "                \n",
    "                # تدريب متنبئ النجاح\n",
    "                self.models['success_predictor'].fit(X_selected, y)\n",
    "                cv_scores_mlp = cross_val_score(self.models['success_predictor'], X_selected, y, cv=cv_folds)\n",
    "                \n",
    "                mean_score_mlp, ci_low_mlp, ci_high_mlp = calculate_confidence_interval(cv_scores_mlp)\n",
    "                results['success_predictor'] = mean_score_mlp\n",
    "                confidence_intervals['success_predictor'] = (ci_low_mlp, ci_high_mlp)\n",
    "                self.model_stats['cross_val_scores']['success_predictor'] = cv_scores_mlp.tolist()\n",
    "                \n",
    "                # تدريب محسن النقر\n",
    "                self.models['click_optimizer'].fit(X_selected, y)\n",
    "                cv_scores_opt = cross_val_score(self.models['click_optimizer'], X_selected, y, cv=cv_folds)\n",
    "                \n",
    "                mean_score_opt, ci_low_opt, ci_high_opt = calculate_confidence_interval(cv_scores_opt)\n",
    "                results['click_optimizer'] = mean_score_opt\n",
    "                confidence_intervals['click_optimizer'] = (ci_low_opt, ci_high_opt)\n",
    "                self.model_stats['cross_val_scores']['click_optimizer'] = cv_scores_opt.tolist()\n",
    "            \n",
    "            # تدريب كاشف الشذوذ\n",
    "            self.models['anomaly_detector'].fit(X_selected)\n",
    "            \n",
    "            # حفظ إحصائيات التدريب\n",
    "            self.model_stats['training_samples'] = len(training_samples)\n",
    "            self.model_stats['last_training'] = datetime.now().isoformat()\n",
    "            self.model_stats['accuracy_scores'] = results\n",
    "            self.model_stats['confidence_intervals'] = confidence_intervals\n",
    "            \n",
    "            # حفظ أهمية الميزات\n",
    "            if hasattr(self.models['region_classifier'], 'feature_importances_'):\n",
    "                importances = self.models['region_classifier'].feature_importances_\n",
    "                if len(feature_names) == len(importances):\n",
    "                    self.model_stats['feature_importance'] = dict(zip(feature_names, importances.tolist()))\n",
    "            \n",
    "            self.is_trained = True\n",
    "            self._save_models()\n",
    "            \n",
    "            logging.info(f\"تم تدريب النماذج بنجاح. النتائج: {results}\")\n",
    "            if HAS_STATSMODELS:\n",
    "                logging.info(f\"فترات الثقة: {confidence_intervals}\")\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في تدريب النماذج: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def predict_best_regions(self, image: np.ndarray, num_regions: int = 5) -> List[Dict]:\n",
    "        \"\"\"التنبؤ بأفضل المناطق للنقر\"\"\"\n",
    "        try:\n",
    "            if not self.is_trained:\n",
    "                logging.warning(\"النماذج غير مدربة، سيتم استخدام التنبؤ الافتراضي\")\n",
    "                return self._get_default_predictions(image, num_regions)\n",
    "            \n",
    "            # استخراج الميزات\n",
    "            features = self.feature_extractor.extract_comprehensive_features(image)\n",
    "            feature_vector = np.array([list(features.values())]).reshape(1, -1)\n",
    "            \n",
    "            # تطبيع البيانات\n",
    "            feature_vector_scaled = self.scalers['robust'].transform(feature_vector)\n",
    "            \n",
    "            # اختيار الميزات\n",
    "            if hasattr(self.feature_selector, 'transform'):\n",
    "                feature_vector_selected = self.feature_selector.transform(feature_vector_scaled)\n",
    "            else:\n",
    "                feature_vector_selected = feature_vector_scaled\n",
    "            \n",
    "            predictions = []\n",
    "            \n",
    "            # التنبؤ باستخدام النماذج المختلفة\n",
    "            for model_name, model in self.models.items():\n",
    "                if model_name == 'anomaly_detector':\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    if hasattr(model, 'predict_proba'):\n",
    "                        proba = model.predict_proba(feature_vector_selected)[0]\n",
    "                        confidence = np.max(proba)\n",
    "                        prediction = np.argmax(proba)\n",
    "                    else:\n",
    "                        prediction = model.predict(feature_vector_selected)[0]\n",
    "                        confidence = 0.5\n",
    "                    \n",
    "                    predictions.append({\n",
    "                        'model': model_name,\n",
    "                        'prediction': int(prediction),\n",
    "                        'confidence': float(confidence),\n",
    "                        'features_used': len(feature_vector_selected[0])\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"خطأ في التنبؤ بالنموذج {model_name}: {e}\")\n",
    "            \n",
    "            # دمج التنبؤات\n",
    "            ensemble_predictions = self._ensemble_predictions(predictions, image)\n",
    "            \n",
    "            return ensemble_predictions[:num_regions]\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في التنبؤ بالمناطق: {e}\")\n",
    "            return self._get_default_predictions(image, num_regions)\n",
    "    \n",
    "    def _ensemble_predictions(self, predictions: List[Dict], image: np.ndarray) -> List[Dict]:\n",
    "        \"\"\"دمج تنبؤات النماذج المختلفة\"\"\"\n",
    "        try:\n",
    "            h, w = image.shape[:2]\n",
    "            \n",
    "            # إنشاء مناطق مرشحة بناءً على التنبؤات\n",
    "            candidate_regions = []\n",
    "            \n",
    "            # مناطق مركزية (عادة مفيدة للكابتشا)\n",
    "            center_regions = [\n",
    "                {'x': w//2, 'y': h//2, 'source': 'center', 'base_confidence': 0.7},\n",
    "                {'x': w//3, 'y': h//2, 'source': 'left_center', 'base_confidence': 0.6},\n",
    "                {'x': 2*w//3, 'y': h//2, 'source': 'right_center', 'base_confidence': 0.6},\n",
    "                {'x': w//2, 'y': h//3, 'source': 'top_center', 'base_confidence': 0.5},\n",
    "                {'x': w//2, 'y': 2*h//3, 'source': 'bottom_center', 'base_confidence': 0.5}\n",
    "            ]\n",
    "            \n",
    "            # تعديل الثقة بناءً على تنبؤات النماذج\n",
    "            for region in center_regions:\n",
    "                total_confidence = region['base_confidence']\n",
    "                model_count = 0\n",
    "                \n",
    "                for pred in predictions:\n",
    "                    if pred['prediction'] == 1:  # تنبؤ إيجابي\n",
    "                        total_confidence += pred['confidence'] * 0.3\n",
    "                        model_count += 1\n",
    "                \n",
    "                # تطبيع الثقة\n",
    "                if model_count > 0:\n",
    "                    total_confidence = total_confidence / (1 + model_count * 0.3)\n",
    "                \n",
    "                region['confidence'] = min(0.95, total_confidence)\n",
    "                region['models_agreement'] = model_count\n",
    "                \n",
    "                candidate_regions.append(region)\n",
    "            \n",
    "            # ترتيب حسب الثقة\n",
    "            candidate_regions.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "            \n",
    "            return candidate_regions\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في دمج التنبؤات: {e}\")\n",
    "            return self._get_default_predictions(image, 5)\n",
    "    \n",
    "    def _get_default_predictions(self, image: np.ndarray, num_regions: int) -> List[Dict]:\n",
    "        \"\"\"تنبؤات افتراضية في حالة عدم وجود نماذج مدربة\"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        default_regions = [\n",
    "            {'x': w//2, 'y': h//2, 'confidence': 0.5, 'source': 'default_center'},\n",
    "            {'x': w//3, 'y': h//2, 'confidence': 0.4, 'source': 'default_left'},\n",
    "            {'x': 2*w//3, 'y': h//2, 'confidence': 0.4, 'source': 'default_right'},\n",
    "            {'x': w//2, 'y': h//3, 'confidence': 0.3, 'source': 'default_top'},\n",
    "            {'x': w//2, 'y': 2*h//3, 'confidence': 0.3, 'source': 'default_bottom'}\n",
    "        ]\n",
    "        \n",
    "        return default_regions[:num_regions]\n",
    "    \n",
    "    def detect_anomaly(self, features: Dict[str, float]) -> Dict[str, Union[bool, float]]:\n",
    "        \"\"\"كشف الشذوذ في الميزات\"\"\"\n",
    "        try:\n",
    "            if not self.is_trained or 'anomaly_detector' not in self.models:\n",
    "                return {'is_anomaly': False, 'anomaly_score': 0.0}\n",
    "            \n",
    "            feature_vector = np.array([list(features.values())]).reshape(1, -1)\n",
    "            feature_vector_scaled = self.scalers['robust'].transform(feature_vector)\n",
    "            \n",
    "            # كشف الشذوذ\n",
    "            anomaly_prediction = self.models['anomaly_detector'].predict(feature_vector_scaled)[0]\n",
    "            anomaly_score = self.models['anomaly_detector'].score_samples(feature_)\n",
    "            anomaly_score = self.models['anomaly_detector'].score_samples(feature_vector_scaled)[0]\n",
    "            \n",
    "            return {\n",
    "                'is_anomaly': anomaly_prediction == -1,\n",
    "                'anomaly_score': float(anomaly_score),\n",
    "                'confidence': abs(float(anomaly_score))\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في كشف الشذوذ: {e}\")\n",
    "            return {'is_anomaly': False, 'anomaly_score': 0.0}\n",
    "\n",
    "# ================================\n",
    "# Advanced Template Matcher\n",
    "# ================================\n",
    "\n",
    "class AdvancedTemplateMatcher:\n",
    "    \"\"\"مطابق القوالب المتقدم مع مقاومة التغييرات\"\"\"\n",
    "    \n",
    "    def __init__(self, config_manager: SecureConfigManager):\n",
    "        self.config_manager = config_manager\n",
    "        self.templates = {}\n",
    "        self.template_features = {}\n",
    "        self.matching_cache = {}\n",
    "        self.cache_timeout = 1.0\n",
    "        \n",
    "        # إعدادات المطابقة المتقدمة\n",
    "        self.scale_range = np.linspace(0.7, 1.3, 7)\n",
    "        self.rotation_range = [-5, -2, 0, 2, 5]\n",
    "        self.methods = [\n",
    "            cv2.TM_CCOEFF_NORMED,\n",
    "            cv2.TM_CCORR_NORMED,\n",
    "            cv2.TM_SQDIFF_NORMED\n",
    "        ]\n",
    "        \n",
    "        self.feature_extractor = AdvancedFeatureExtractor()\n",
    "        self._load_templates()\n",
    "    \n",
    "    def _load_templates(self):\n",
    "        \"\"\"تحميل القوالب مع معالجة الأخطاء المتقدمة\"\"\"\n",
    "        template_names = ['recaptcha', 'verified', 'done', 'google']\n",
    "        \n",
    "        for name in template_names:\n",
    "            try:\n",
    "                template_path = self.config_manager.get_template_path(name)\n",
    "                \n",
    "                if template_path.exists():\n",
    "                    template = cv2.imread(str(template_path), cv2.IMREAD_COLOR)\n",
    "                    if template is not None:\n",
    "                        self.templates[name] = template\n",
    "                        self.template_features[name] = self.feature_extractor.extract_comprehensive_features(template)\n",
    "                        logging.info(f\"تم تحميل قالب {name} بنجاح\")\n",
    "                    else:\n",
    "                        logging.warning(f\"فشل في قراءة قالب {name}\")\n",
    "                        self._create_fallback_template(name)\n",
    "                else:\n",
    "                    logging.warning(f\"قالب {name} غير موجود في {template_path}\")\n",
    "                    self._create_fallback_template(name)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logging.error(f\"خطأ في تحميل قالب {name}: {e}\")\n",
    "                self._create_fallback_template(name)\n",
    "    \n",
    "    def _create_fallback_template(self, name: str):\n",
    "        \"\"\"إنشاء قالب احتياطي\"\"\"\n",
    "        try:\n",
    "            fallback_template = np.zeros((50, 100, 3), dtype=np.uint8)\n",
    "            cv2.putText(fallback_template, name.upper(), (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            self.templates[name] = fallback_template\n",
    "            self.template_features[name] = self.feature_extractor.extract_comprehensive_features(fallback_template)\n",
    "            \n",
    "            logging.info(f\"تم إنشاء قالب احتياطي لـ {name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"فشل في إنشاء قالب احتياطي لـ {name}: {e}\")\n",
    "    \n",
    "    def find_template_advanced(self, template_name: str, image: np.ndarray, \n",
    "                             threshold: float = 0.8) -> Optional[Dict]:\n",
    "        \"\"\"البحث المتقدم عن القالب مع مقاومة التغييرات\"\"\"\n",
    "        try:\n",
    "            if template_name not in self.templates:\n",
    "                logging.warning(f\"قالب {template_name} غير موجود\")\n",
    "                return None\n",
    "            \n",
    "            # فحص الكاش\n",
    "            cache_key = f\"{template_name}_{hash(image.tobytes())}\"\n",
    "            current_time = time.time()\n",
    "            \n",
    "            if cache_key in self.matching_cache:\n",
    "                cached_result = self.matching_cache[cache_key]\n",
    "                if current_time - cached_result['timestamp'] < self.cache_timeout:\n",
    "                    return cached_result['result']\n",
    "            \n",
    "            template = self.templates[template_name]\n",
    "            best_match = None\n",
    "            best_confidence = 0\n",
    "            \n",
    "            # البحث مع تحويلات متعددة\n",
    "            for scale in self.scale_range:\n",
    "                for rotation in self.rotation_range:\n",
    "                    try:\n",
    "                        transformed_template = self._transform_template(template, scale, rotation)\n",
    "                        \n",
    "                        if transformed_template is None:\n",
    "                            continue\n",
    "                        \n",
    "                        for method in self.methods:\n",
    "                            match_result = self._match_template_method(\n",
    "                                image, transformed_template, method, threshold\n",
    "                            )\n",
    "                            \n",
    "                            if match_result and match_result['confidence'] > best_confidence:\n",
    "                                best_match = match_result\n",
    "                                best_match['scale'] = scale\n",
    "                                best_match['rotation'] = rotation\n",
    "                                best_match['method'] = method\n",
    "                                best_confidence = match_result['confidence']\n",
    "                                \n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "            \n",
    "            # التحقق من المطابقة باستخدام الميزات\n",
    "            if best_match:\n",
    "                feature_similarity = self._verify_match_with_features(\n",
    "                    image, best_match, template_name\n",
    "                )\n",
    "                best_match['feature_similarity'] = feature_similarity\n",
    "                best_match['final_confidence'] = (\n",
    "                    best_match['confidence'] * 0.7 + feature_similarity * 0.3\n",
    "                )\n",
    "            \n",
    "            # حفظ في الكاش\n",
    "            self.matching_cache[cache_key] = {\n",
    "                'result': best_match,\n",
    "                'timestamp': current_time\n",
    "            }\n",
    "            \n",
    "            self._cleanup_cache()\n",
    "            \n",
    "            return best_match\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في البحث المتقدم عن {template_name}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _transform_template(self, template: np.ndarray, scale: float, rotation: float) -> Optional[np.ndarray]:\n",
    "        \"\"\"تطبيق التحويلات على القالب\"\"\"\n",
    "        try:\n",
    "            h, w = template.shape[:2]\n",
    "            \n",
    "            new_w, new_h = int(w * scale), int(h * scale)\n",
    "            if new_w <= 0 or new_h <= 0:\n",
    "                return None\n",
    "            \n",
    "            scaled = cv2.resize(template, (new_w, new_h))\n",
    "            \n",
    "            if abs(rotation) > 0.1:\n",
    "                center = (new_w // 2, new_h // 2)\n",
    "                rotation_matrix = cv2.getRotationMatrix2D(center, rotation, 1.0)\n",
    "                rotated = cv2.warpAffine(scaled, rotation_matrix, (new_w, new_h))\n",
    "                return rotated\n",
    "            \n",
    "            return scaled\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    def _match_template_method(self, image: np.ndarray, template: np.ndarray, \n",
    "                             method: int, threshold: float) -> Optional[Dict]:\n",
    "        \"\"\"مطابقة القالب بطريقة محددة\"\"\"\n",
    "        try:\n",
    "            if template.shape[0] > image.shape[0] or template.shape[1] > image.shape[1]:\n",
    "                return None\n",
    "            \n",
    "            result = cv2.matchTemplate(image, template, method)\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "            \n",
    "            if method == cv2.TM_SQDIFF_NORMED:\n",
    "                confidence = 1 - min_val\n",
    "                location = min_loc\n",
    "            else:\n",
    "                confidence = max_val\n",
    "                location = max_loc\n",
    "            \n",
    "            if confidence >= threshold:\n",
    "                h, w = template.shape[:2]\n",
    "                center_x = location[0] + w // 2\n",
    "                center_y = location[1] + h // 2\n",
    "                \n",
    "                return {\n",
    "                    'x': center_x,\n",
    "                    'y': center_y,\n",
    "                    'width': w,\n",
    "                    'height': h,\n",
    "                    'confidence': float(confidence),\n",
    "                    'location': location,\n",
    "                    'template_size': (w, h)\n",
    "                }\n",
    "            \n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    def _verify_match_with_features(self, image: np.ndarray, match: Dict, template_name: str) -> float:\n",
    "        \"\"\"التحقق من المطابقة باستخدام الميزات\"\"\"\n",
    "        try:\n",
    "            x, y = match['location']\n",
    "            w, h = match['template_size']\n",
    "            \n",
    "            if x + w > image.shape[1] or y + h > image.shape[0]:\n",
    "                return 0.0\n",
    "            \n",
    "            matched_region = image[y:y+h, x:x+w]\n",
    "            region_features = self.feature_extractor.extract_comprehensive_features(matched_region)\n",
    "            \n",
    "            template_features = self.template_features.get(template_name, {})\n",
    "            \n",
    "            if not template_features or not region_features:\n",
    "                return 0.5\n",
    "            \n",
    "            similarity = self._calculate_feature_similarity(region_features, template_features)\n",
    "            return similarity\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في التحقق من الميزات: {e}\")\n",
    "            return 0.5\n",
    "    \n",
    "    def _calculate_feature_similarity(self, features1: Dict, features2: Dict) -> float:\n",
    "        \"\"\"حساب التشابه بين الميزات\"\"\"\n",
    "        try:\n",
    "            common_keys = set(features1.keys()) & set(features2.keys())\n",
    "            if not common_keys:\n",
    "                return 0.0\n",
    "            \n",
    "            similarities = []\n",
    "            for key in common_keys:\n",
    "                val1, val2 = features1[key], features2[key]\n",
    "                \n",
    "                if val1 == 0 and val2 == 0:\n",
    "                    sim = 1.0\n",
    "                elif val1 == 0 or val2 == 0:\n",
    "                    sim = 0.0\n",
    "                else:\n",
    "                    diff = abs(val1 - val2)\n",
    "                    max_val = max(abs(val1), abs(val2))\n",
    "                    sim = 1.0 - (diff / max_val)\n",
    "                \n",
    "                similarities.append(max(0.0, sim))\n",
    "            \n",
    "            return np.mean(similarities)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return 0.0\n",
    "    \n",
    "    def _cleanup_cache(self):\n",
    "        \"\"\"تنظيف كاش المطابقة\"\"\"\n",
    "        try:\n",
    "            current_time = time.time()\n",
    "            expired_keys = [\n",
    "                key for key, value in self.matching_cache.items()\n",
    "                if current_time - value['timestamp'] > self.cache_timeout * 2\n",
    "            ]\n",
    "            \n",
    "            for key in expired_keys:\n",
    "                del self.matching_cache[key]\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في تنظيف كاش المطابقة: {e}\")\n",
    "\n",
    "# ================================\n",
    "# Smart Screenshot Manager\n",
    "# ================================\n",
    "\n",
    "class SmartScreenshotManager:\n",
    "    \"\"\"مدير لقطات الشاشة الذكي\"\"\"\n",
    "    \n",
    "    def __init__(self, config: PerformanceConfig):\n",
    "        self.config = config\n",
    "        self.frame_buffer = deque(maxlen=config.frame_buffer_size)\n",
    "        self.last_screenshot = None\n",
    "        self.screenshot_cache = {}\n",
    "        self.cache_timeout = 0.5\n",
    "        \n",
    "    def capture_smart_screenshot(self, force_full: bool = False) -> Optional[np.ndarray]:\n",
    "        \"\"\"التقاط لقطة شاشة ذكية\"\"\"\n",
    "        try:\n",
    "            current_time = time.time()\n",
    "            \n",
    "            if not force_full and self.last_screenshot is not None:\n",
    "                if current_time - self.screenshot_cache.get('timestamp', 0) < self.cache_timeout:\n",
    "                    return self.last_screenshot\n",
    "            \n",
    "            with mss.mss() as sct:\n",
    "                monitor = sct.monitors[1]\n",
    "                screenshot = np.array(sct.grab(monitor))\n",
    "                img = cv2.cvtColor(screenshot, cv2.COLOR_BGRA2BGR)\n",
    "                \n",
    "                if self.config.adaptive_quality:\n",
    "                    img = self._adaptive_resize(img)\n",
    "                \n",
    "                self.last_screenshot = img\n",
    "                self.screenshot_cache = {'timestamp': current_time}\n",
    "                self.frame_buffer.append({'image': img, 'timestamp': current_time})\n",
    "                \n",
    "                return img\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في التقاط الشاشة: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _adaptive_resize(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"تغيير حجم تكيفي للصورة\"\"\"\n",
    "        try:\n",
    "            h, w = img.shape[:2]\n",
    "            max_w, max_h = self.config.max_screenshot_resolution\n",
    "            \n",
    "            if w <= max_w and h <= max_h:\n",
    "                return img\n",
    "            \n",
    "            scale_w = max_w / w\n",
    "            scale_h = max_h / h\n",
    "            scale = min(scale_w, scale_h)\n",
    "            \n",
    "            new_w = int(w * scale)\n",
    "            new_h = int(h * scale)\n",
    "            \n",
    "            resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "            return resized\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في تغيير حجم الصورة: {e}\")\n",
    "            return img\n",
    "    \n",
    "    def cleanup_cache(self):\n",
    "        \"\"\"تنظيف الكاش\"\"\"\n",
    "        try:\n",
    "            self.screenshot_cache.clear()\n",
    "            if len(self.frame_buffer) > self.config.frame_buffer_size // 2:\n",
    "                keep_count = self.config.frame_buffer_size // 2\n",
    "                self.frame_buffer = deque(list(self.frame_buffer)[-keep_count:], \n",
    "                                        maxlen=self.config.frame_buffer_size)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في تنظيف كاش الصور: {e}\")\n",
    "\n",
    "# ================================\n",
    "# Intelligent Click Manager\n",
    "# ================================\n",
    "\n",
    "class IntelligentClickManager:\n",
    "    \"\"\"مدير النقر الذكي مع تعلم الأنماط\"\"\"\n",
    "    \n",
    "    def __init__(self, config_manager: SecureConfigManager, learning_engine: AdaptiveLearningEngine):\n",
    "        self.config_manager = config_manager\n",
    "        self.learning_engine = learning_engine\n",
    "        self.click_history = deque(maxlen=100)\n",
    "        self.last_click_time = 0\n",
    "        \n",
    "    def smart_click(self, target_info: Dict, element_type: str) -> bool:\n",
    "        \"\"\"نقر ذكي مع تعلم الأنماط\"\"\"\n",
    "        try:\n",
    "            current_time = time.time()\n",
    "            \n",
    "            # الحصول على التأخير الأمثل من التعلم\n",
    "            optimal_delay = self.learning_engine.get_optimal_click_delay(element_type)\n",
    "            \n",
    "            if current_time - self.last_click_time < optimal_delay:\n",
    "                time.sleep(optimal_delay - (current_time - self.last_click_time))\n",
    "            \n",
    "            # تحسين نقطة النقر باستخدام التعلم\n",
    "            base_position = (target_info.get('x', 0), target_info.get('y', 0))\n",
    "            confidence = target_info.get('confidence', 0.5)\n",
    "            \n",
    "            optimized_position = self.learning_engine.predict_optimal_click_position(\n",
    "                element_type, base_position, confidence\n",
    "            )\n",
    "            \n",
    "            # تنفيذ النقر\n",
    "            success = self._execute_click(optimized_position, optimal_delay, element_type)\n",
    "            \n",
    "            # تسجيل النتيجة للتعلم\n",
    "            self.learning_engine.learn_from_click_pattern(\n",
    "                optimized_position, element_type, success, confidence,\n",
    "                context={'original_position': base_position, 'delay_used': optimal_delay}\n",
    "            )\n",
    "            \n",
    "            # تسجيل في التاريخ\n",
    "            self._record_click(optimized_position, element_type, success, target_info)\n",
    "            \n",
    "            self.last_click_time = time.time()\n",
    "            \n",
    "            return success\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في النقر الذكي: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _execute_click(self, click_point: Tuple[int, int], delay: float, element_type: str) -> bool:\n",
    "        \"\"\"تنفيذ النقر مع معالجة الأخطاء\"\"\"\n",
    "        try:\n",
    "            x, y = click_point\n",
    "            \n",
    "            if x < 0 or y < 0 or x > 3840 or y > 2160:\n",
    "                logging.warning(f\"إحداثيات نقر غير صالحة: ({x}, {y})\")\n",
    "                return False\n",
    "            \n",
    "            current_x, current_y = pyautogui.position()\n",
    "            distance = np.sqrt((x - current_x)**2 + (y - current_y)**2)\n",
    "            move_time = min(delay, distance / 1000)\n",
    "            \n",
    "            pyautogui.moveTo(x, y, duration=move_time, tween=pyautogui.easeOutQuad)\n",
    "            time.sleep(0.05)\n",
    "            pyautogui.click()\n",
    "            \n",
    "            logging.info(f\"تم النقر على {element_type} في ({x}, {y}) بتأخير {delay:.3f}s\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في تنفيذ النقر: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _record_click(self, click_point: Tuple[int, int], element_type: str, \n",
    "                     success: bool, target_info: Dict):\n",
    "        \"\"\"تسجيل النقر في التاريخ\"\"\"\n",
    "        try:\n",
    "            click_record = {\n",
    "                'timestamp': time.time(),\n",
    "                'point': click_point,\n",
    "                'element_type': element_type,\n",
    "                'success': success,\n",
    "                'confidence': target_info.get('confidence', 0.0),\n",
    "                'target_info': target_info.copy()\n",
    "            }\n",
    "            \n",
    "            self.click_history.append(click_record)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في تسجيل النقر: {e}\")\n",
    "    \n",
    "    def get_click_statistics(self) -> Dict:\n",
    "        \"\"\"الحصول على إحصائيات النقر\"\"\"\n",
    "        try:\n",
    "            stats = {\n",
    "                'total_clicks': len(self.click_history),\n",
    "                'success_rate': 0.0,\n",
    "                'element_stats': {}\n",
    "            }\n",
    "            \n",
    "            if self.click_history:\n",
    "                successful_clicks = sum(1 for c in self.click_history if c['success'])\n",
    "                stats['success_rate'] = successful_clicks / len(self.click_history)\n",
    "            \n",
    "            for element_type in ['recaptcha', 'verified', 'done', 'google']:\n",
    "                element_clicks = [c for c in self.click_history if c['element_type'] == element_type]\n",
    "                \n",
    "                if element_clicks:\n",
    "                    element_success = sum(1 for c in element_clicks if c['success'])\n",
    "                    stats['element_stats'][element_type] = {\n",
    "                        'total': len(element_clicks),\n",
    "                        'successful': element_success,\n",
    "                        'success_rate': element_success / len(element_clicks),\n",
    "                        'avg_confidence': np.mean([c['confidence'] for c in element_clicks])\n",
    "                    }\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في حساب إحصائيات النقر: {e}\")\n",
    "            return {'total_clicks': 0, 'success_rate': 0.0}\n",
    "\n",
    "# ================================\n",
    "# Advanced Wait Manager\n",
    "# ================================\n",
    "\n",
    "class AdvancedWaitManager:\n",
    "    \"\"\"مدير الانتظار المتقدم مع تعلم الأوقات المثلى\"\"\"\n",
    "    \n",
    "    def __init__(self, config_manager: SecureConfigManager, template_matcher: AdvancedTemplateMatcher,  learning_engine: AdaptiveLearningEngine):\n",
    "        self.config_manager = config_manager\n",
    "        self.template_matcher = template_matcher\n",
    "        self.learning_engine = learning_engine\n",
    "        self.wait_history = deque(maxlen=50)\n",
    "        self.check_interval = 0.2\n",
    "        \n",
    "    def smart_wait_for_element(self, target_elements: List[str], timeout: float = None,  context: str = \"general\") -> Optional[Dict]:\n",
    "        \"\"\"انتظار ذكي لظهور عنصر من قائمة العناصر\"\"\"\n",
    "        try:\n",
    "            if timeout is None:\n",
    "                timeout = self.learning_engine.get_optimal_timeout(context)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            last_check_time = 0\n",
    "            check_count = 0\n",
    "            \n",
    "            logging.info(f\"بدء الانتظار الذكي لـ {target_elements} لمدة {timeout:.1f}s\")\n",
    "            \n",
    "            while time.time() - start_time < timeout:\n",
    "                current_time = time.time()\n",
    "                \n",
    "                if current_time - last_check_time < self._get_adaptive_check_interval(context, check_count):\n",
    "                    time.sleep(0.05)\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    screenshot = self._capture_for_wait()\n",
    "                    if screenshot is None:\n",
    "                        time.sleep(self.check_interval)\n",
    "                        continue\n",
    "                    \n",
    "                    for element_name in target_elements:\n",
    "                        # استخدام العتبة المثلى من التعلم\n",
    "                        optimal_threshold = self.learning_engine.get_optimal_confidence_threshold(element_name)\n",
    "                        \n",
    "                        detection = self.template_matcher.find_template_advanced(\n",
    "                            element_name, screenshot, threshold=optimal_threshold\n",
    "                        )\n",
    "                        \n",
    "                        if detection and detection.get('final_confidence', 0) > optimal_threshold:\n",
    "                            elapsed = time.time() - start_time\n",
    "                            \n",
    "                            # تعلم من النجاح\n",
    "                            self.learning_engine.learn_from_timing(\n",
    "                                f'{context}_wait', elapsed, True,\n",
    "                                context={'element': element_name, 'threshold_used': optimal_threshold}\n",
    "                            )\n",
    "                            \n",
    "                            self._record_wait_success(element_name, elapsed, context)\n",
    "                            \n",
    "                            logging.info(f\"✅ تم العثور على {element_name} خلال {elapsed:.2f}s\")\n",
    "                            \n",
    "                            return {\n",
    "                                'element': element_name,\n",
    "                                'detection': detection,\n",
    "                                'elapsed_time': elapsed,\n",
    "                                'success': True\n",
    "                            }\n",
    "                    \n",
    "                    last_check_time = current_time\n",
    "                    check_count += 1\n",
    "                    \n",
    "                    if check_count % 25 == 0:\n",
    "                        remaining = timeout - (current_time - start_time)\n",
    "                        logging.info(f\"⏳ انتظار {target_elements}... متبقي: {remaining:.1f}s\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"خطأ في فحص الانتظار: {e}\")\n",
    "                    time.sleep(self.check_interval)\n",
    "                    continue\n",
    "            \n",
    "            # انتهاء المهلة\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            # تعلم من الفشل\n",
    "            self.learning_engine.learn_from_timing(\n",
    "                f'{context}_wait', elapsed, False,\n",
    "                context={'elements': target_elements, 'timeout_used': timeout}\n",
    "            )\n",
    "            \n",
    "            self._record_wait_timeout(target_elements, elapsed, context)\n",
    "            \n",
    "            logging.warning(f\"⏰ انتهت مهلة انتظار {target_elements} ({elapsed:.1f}s)\")\n",
    "            \n",
    "            return {\n",
    "                'element': None,\n",
    "                'detection': None,\n",
    "                'elapsed_time': elapsed,\n",
    "                'success': False,\n",
    "                'reason': 'timeout'\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في الانتظار الذكي: {e}\")\n",
    "            return {\n",
    "                'element': None,\n",
    "                'detection': None,\n",
    "                'elapsed_time': 0,\n",
    "                'success': False,\n",
    "                'reason': 'error'\n",
    "            }\n",
    "    \n",
    "    def _get_adaptive_check_interval(self, context: str, check_count: int) -> float:\n",
    "        \"\"\"حساب فترة الفحص التكيفية\"\"\"\n",
    "        try:\n",
    "            base_interval = self.check_interval\n",
    "            \n",
    "            if check_count < 10:\n",
    "                return base_interval * 0.5\n",
    "            \n",
    "            if check_count > 50:\n",
    "                return base_interval * 1.5\n",
    "            \n",
    "            context_multipliers = {\n",
    "                'verified': 0.8,\n",
    "                'success': 1.0,\n",
    "                'general': 1.2\n",
    "            }\n",
    "            \n",
    "            return base_interval * context_multipliers.get(context, 1.0)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return self.check_interval\n",
    "    \n",
    "    def _capture_for_wait(self) -> Optional[np.ndarray]:\n",
    "        \"\"\"التقاط محسن للانتظار\"\"\"\n",
    "        try:\n",
    "            with mss.mss() as sct:\n",
    "                monitor = sct.monitors[1]\n",
    "                screenshot = np.array(sct.grab(monitor))\n",
    "                return cv2.cvtColor(screenshot, cv2.COLOR_BGRA2BGR)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في التقاط الشاشة للانتظار: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _record_wait_success(self, element: str, elapsed_time: float, context: str):\n",
    "        \"\"\"تسجيل نجاح الانتظار\"\"\"\n",
    "        try:\n",
    "            record = {\n",
    "                'timestamp': time.time(),\n",
    "                'element': element,\n",
    "                'elapsed_time': elapsed_time,\n",
    "                'context': context,\n",
    "                'success': True\n",
    "            }\n",
    "            \n",
    "            self.wait_history.append(record)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في تسجيل نجاح الانتظار: {e}\")\n",
    "    \n",
    "    def _record_wait_timeout(self, elements: List[str], elapsed_time: float, context: str):\n",
    "        \"\"\"تسجيل انتهاء مهلة الانتظار\"\"\"\n",
    "        try:\n",
    "            record = {\n",
    "                'timestamp': time.time(),\n",
    "                'elements': elements,\n",
    "                'elapsed_time': elapsed_time,\n",
    "                'context': context,\n",
    "                'success': False,\n",
    "                'reason': 'timeout'\n",
    "            }\n",
    "            \n",
    "            self.wait_history.append(record)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في تسجيل انتهاء المهلة: {e}\")\n",
    "    \n",
    "    def get_wait_statistics(self) -> Dict:\n",
    "        \"\"\"الحصول على إحصائيات الانتظار\"\"\"\n",
    "        try:\n",
    "            if not self.wait_history:\n",
    "                return {'total_waits': 0, 'success_rate': 0.0}\n",
    "            \n",
    "            total_waits = len(self.wait_history)\n",
    "            successful_waits = sum(1 for w in self.wait_history if w.get('success', False))\n",
    "            \n",
    "            stats = {\n",
    "                'total_waits': total_waits,\n",
    "                'successful_waits': successful_waits,\n",
    "                'success_rate': successful_waits / total_waits,\n",
    "                'avg_wait_time': np.mean([w.get('elapsed_time', 0) for w in self.wait_history]),\n",
    "                'context_stats': {}\n",
    "            }\n",
    "            \n",
    "            for context in ['verified', 'success', 'general']:\n",
    "                context_waits = [w for w in self.wait_history if w.get('context') == context]\n",
    "                \n",
    "                if context_waits:\n",
    "                    context_success = sum(1 for w in context_waits if w.get('success', False))\n",
    "                    stats['context_stats'][context] = {\n",
    "                        'total': len(context_waits),\n",
    "                        'successful': context_success,\n",
    "                        'success_rate': context_success / len(context_waits),\n",
    "                        'avg_time': np.mean([w.get('elapsed_time', 0) for w in context_waits])\n",
    "                    }\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في حساب إحصائيات الانتظار: {e}\")\n",
    "            return {'total_waits': 0, 'success_rate': 0.0}\n",
    "\n",
    "# ================================\n",
    "# Main Advanced Captcha Solver\n",
    "# ================================\n",
    "\n",
    "class AdvancedCaptchaSolver:\n",
    "    \"\"\"حلال الكابتشا المتقدم مع التعلم التكيفي\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # إعداد نظام السجلات\n",
    "        self._setup_logging()\n",
    "        \n",
    "        # تحميل الإعدادات\n",
    "        self.config_manager = SecureConfigManager()\n",
    "        self.security_config = SecurityConfig()\n",
    "        self.performance_config = PerformanceConfig()\n",
    "        self.learning_config = LearningConfig()\n",
    "        \n",
    "        # مراقب الأداء\n",
    "        self.performance_monitor = PerformanceMonitor(self.performance_config)\n",
    "        \n",
    "        # محرك التعلم التكيفي\n",
    "        self.learning_engine = AdaptiveLearningEngine(self.learning_config, self.config_manager)\n",
    "        \n",
    "        # المكونات الأساسية\n",
    "        self.ml_engine = AdvancedMLEngine(self.config_manager)\n",
    "        self.screenshot_manager = SmartScreenshotManager(self.performance_config)\n",
    "        self.template_matcher = AdvancedTemplateMatcher(self.config_manager)\n",
    "        self.click_manager = IntelligentClickManager(self.config_manager, self.learning_engine)\n",
    "        self.wait_manager = AdvancedWaitManager(self.config_manager, self.template_matcher, self.learning_engine)\n",
    "        \n",
    "        # حالة النظام\n",
    "        self.system_state = \"initializing\"\n",
    "        self.current_session = {\n",
    "            'start_time': time.time(),\n",
    "            'cycles_completed': 0,\n",
    "            'captchas_solved': 0,\n",
    "            'errors_encountered': 0,\n",
    "            'last_activity': time.time(),\n",
    "            'last_auto_save': time.time()\n",
    "        }\n",
    "        \n",
    "        # إعدادات الحل\n",
    "        self.solving_strategy = \"adaptive\"\n",
    "        self.max_retry_attempts = 3\n",
    "        self.retry_delay_multiplier = 1.5\n",
    "                # تحميل البيانات المحفوظة\n",
    "        self._load_session_data()\n",
    "        \n",
    "        logging.info(\"🚀 تم تهيئة حلال الكابتشا المتقدم مع التعلم التكيفي بنجاح\")\n",
    "    \n",
    "    def _setup_logging(self):\n",
    "        \"\"\"إعداد نظام السجلات المتقدم\"\"\"\n",
    "        try:\n",
    "            logs_dir = Path(\"logs\")\n",
    "            logs_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            log_format = '%(asctime)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'\n",
    "            log_filename = logs_dir / f\"captcha_solver_{datetime.now().strftime('%Y%m%d')}.log\"\n",
    "            \n",
    "            logging.basicConfig(\n",
    "                level=logging.INFO,\n",
    "                format=log_format,\n",
    "                handlers=[\n",
    "                    logging.FileHandler(log_filename, encoding='utf-8'),\n",
    "                    logging.StreamHandler()\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"خطأ في إعداد السجلات: {e}\")\n",
    "    \n",
    "    def _load_session_data(self):\n",
    "        \"\"\"تحميل بيانات الجلسة المحفوظة\"\"\"\n",
    "        try:\n",
    "            session_file = self.config_manager.get_secure_path('PATHS', 'memory_dir', 'session_data.json')\n",
    "            \n",
    "            if session_file.exists():\n",
    "                with open(session_file, 'r', encoding='utf-8') as f:\n",
    "                    saved_session = json.load(f)\n",
    "                    \n",
    "                self.current_session.update({\n",
    "                    'total_captchas_solved': saved_session.get('total_captchas_solved', 0),\n",
    "                    'total_cycles': saved_session.get('total_cycles', 0),\n",
    "                    'best_solving_time': saved_session.get('best_solving_time', float('inf')),\n",
    "                    'success_rate_history': saved_session.get('success_rate_history', [])\n",
    "                })\n",
    "                \n",
    "                logging.info(\"تم تحميل بيانات الجلسة السابقة\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في تحميل بيانات الجلسة: {e}\")\n",
    "    \n",
    "    def _save_session_data(self):\n",
    "        \"\"\"حفظ بيانات الجلسة\"\"\"\n",
    "        try:\n",
    "            session_file = self.config_manager.get_secure_path('PATHS', 'memory_dir', 'session_data.json')\n",
    "            \n",
    "            session_data = {\n",
    "                'last_save': datetime.now().isoformat(),\n",
    "                'total_captchas_solved': self.current_session.get('total_captchas_solved', 0),\n",
    "                'total_cycles': self.current_session.get('total_cycles', 0),\n",
    "                'best_solving_time': self.current_session.get('best_solving_time', float('inf')),\n",
    "                'success_rate_history': self.current_session.get('success_rate_history', []),\n",
    "                'current_session_stats': {\n",
    "                    'cycles_completed': self.current_session['cycles_completed'],\n",
    "                    'captchas_solved': self.current_session['captchas_solved'],\n",
    "                    'errors_encountered': self.current_session['errors_encountered'],\n",
    "                    'session_duration': time.time() - self.current_session['start_time']\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            with open(session_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(session_data, f, indent=2, ensure_ascii=False)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في حفظ بيانات الجلسة: {e}\")\n",
    "    \n",
    "    async def solve_captcha_cycle(self) -> Dict[str, any]:\n",
    "        \"\"\"دورة حل كابتشا واحدة مع التعلم التكيفي\"\"\"\n",
    "        cycle_start_time = time.time()\n",
    "        cycle_result = {\n",
    "            'success': False,\n",
    "            'steps_completed': [],\n",
    "            'errors': [],\n",
    "            'total_time': 0,\n",
    "            'retry_count': 0,\n",
    "            'learning_applied': False\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            logging.info(\"🔄 بدء دورة حل كابتشا جديدة مع التعلم التكيفي\")\n",
    "            \n",
    "            # فحص الموارد\n",
    "            resources = self.performance_monitor.check_resources()\n",
    "            if not resources['memory_ok'] or not resources['cpu_ok']:\n",
    "                logging.warning(f\"⚠️ موارد النظام محدودة: ذاكرة={resources['memory_mb']:.1f}MB، معالج={resources['cpu_percent']:.1f}%\")\n",
    "                \n",
    "                if self.performance_monitor.should_cleanup():\n",
    "                    self.performance_monitor.cleanup_memory()\n",
    "                    self.screenshot_manager.cleanup_cache()\n",
    "            \n",
    "            # الخطوة 1: البحث عن reCAPTCHA مع التعلم\n",
    "            recaptcha_result = await self._find_and_click_recaptcha_adaptive()\n",
    "            cycle_result['steps_completed'].append('recaptcha_search')\n",
    "            \n",
    "            if not recaptcha_result['success']:\n",
    "                if recaptcha_result.get('not_found'):\n",
    "                    cycle_result['success'] = True\n",
    "                    cycle_result['reason'] = 'no_captcha_found'\n",
    "                    return cycle_result\n",
    "                else:\n",
    "                    cycle_result['errors'].append(recaptcha_result.get('error', 'unknown_recaptcha_error'))\n",
    "                    return cycle_result\n",
    "            \n",
    "            cycle_result['learning_applied'] = recaptcha_result.get('learning_applied', False)\n",
    "            \n",
    "            # الخطوة 2: انتظار Verified مع التعلم\n",
    "            verified_result = await self._wait_and_click_verified_adaptive()\n",
    "            cycle_result['steps_completed'].append('verified_wait')\n",
    "            \n",
    "            if not verified_result['success']:\n",
    "                if cycle_result['retry_count'] < self.max_retry_attempts:\n",
    "                    cycle_result['retry_count'] += 1\n",
    "                    logging.info(f\"🔄 إعادة المحاولة {cycle_result['retry_count']}/{self.max_retry_attempts}\")\n",
    "                    \n",
    "                    await asyncio.sleep(self.retry_delay_multiplier * cycle_result['retry_count'])\n",
    "                    return await self.solve_captcha_cycle()\n",
    "                else:\n",
    "                    cycle_result['errors'].append(verified_result.get('error', 'verified_timeout'))\n",
    "                    return cycle_result\n",
    "            \n",
    "            # الخطوة 3: انتظار النجاح النهائي مع التعلم\n",
    "            success_result = await self._wait_for_final_success_adaptive()\n",
    "            cycle_result['steps_completed'].append('success_wait')\n",
    "            \n",
    "            if success_result['success']:\n",
    "                cycle_result['success'] = True\n",
    "                cycle_result['success_element'] = success_result.get('element')\n",
    "                \n",
    "                # تحديث الإحصائيات\n",
    "                self.current_session['captchas_solved'] += 1\n",
    "                solving_time = time.time() - cycle_start_time\n",
    "                \n",
    "                if solving_time < self.current_session.get('best_solving_time', float('inf')):\n",
    "                    self.current_session['best_solving_time'] = solving_time\n",
    "                \n",
    "                logging.info(f\"🎉 تم حل الكابتشا بنجاح في {solving_time:.2f} ثانية مع التعلم التكيفي\")\n",
    "                \n",
    "                # تدريب النماذج على النجاح\n",
    "                await self._update_ml_with_success(cycle_result)\n",
    "                \n",
    "            else:\n",
    "                cycle_result['errors'].append(success_result.get('error', 'final_success_timeout'))\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"❌ خطأ في دورة حل الكابتشا: {e}\")\n",
    "            cycle_result['errors'].append(f\"cycle_exception: {str(e)}\")\n",
    "            self.current_session['errors_encountered'] += 1\n",
    "        \n",
    "        finally:\n",
    "            cycle_result['total_time'] = time.time() - cycle_start_time\n",
    "            self.current_session['cycles_completed'] += 1\n",
    "            self.current_session['last_activity'] = time.time()\n",
    "            \n",
    "            # حفظ تلقائي للتعلم\n",
    "            self.learning_engine.auto_save_if_needed()\n",
    "            \n",
    "            # حفظ تلقائي للجلسة\n",
    "            if self._should_auto_save_session():\n",
    "                self._save_session_data()\n",
    "                self.current_session['last_auto_save'] = time.time()\n",
    "        \n",
    "        return cycle_result\n",
    "    \n",
    "    async def _find_and_click_recaptcha_adaptive(self) -> Dict[str, any]:\n",
    "        \"\"\"البحث والنقر على reCAPTCHA مع التعلم التكيفي\"\"\"\n",
    "        try:\n",
    "            screenshot = self.screenshot_manager.capture_smart_screenshot()\n",
    "            if screenshot is None:\n",
    "                return {'success': False, 'error': 'screenshot_failed'}\n",
    "            \n",
    "            # استخدام العتبة المثلى من التعلم\n",
    "            optimal_threshold = self.learning_engine.get_optimal_confidence_threshold('recaptcha')\n",
    "            \n",
    "            detection = self.template_matcher.find_template_advanced('recaptcha', screenshot, threshold=optimal_threshold)\n",
    "            \n",
    "            if not detection:\n",
    "                return {'success': False, 'not_found': True}\n",
    "            \n",
    "            # استخراج الميزات للتعلم\n",
    "            region = self._extract_detection_region(screenshot, detection)\n",
    "            features = self.ml_engine.feature_extractor.extract_comprehensive_features(region)\n",
    "            \n",
    "            # كشف الشذوذ\n",
    "            anomaly_result = self.ml_engine.detect_anomaly(features)\n",
    "            if anomaly_result['is_anomaly']:\n",
    "                logging.warning(f\"⚠️ تم كشف شذوذ في reCAPTCHA: {anomaly_result['anomaly_score']:.3f}\")\n",
    "            \n",
    "            # النقر الذكي مع التعلم\n",
    "            click_success = self.click_manager.smart_click(detection, 'recaptcha')\n",
    "            \n",
    "            if click_success:\n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'detection': detection,\n",
    "                    'features': features,\n",
    "                    'anomaly_detected': anomaly_result['is_anomaly'],\n",
    "                    'learning_applied': True,\n",
    "                    'threshold_used': optimal_threshold\n",
    "                }\n",
    "            else:\n",
    "                return {'success': False, 'error': 'click_failed'}\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في البحث عن reCAPTCHA: {e}\")\n",
    "            return {'success': False, 'error': f'exception: {str(e)}'}\n",
    "    \n",
    "    async def _wait_and_click_verified_adaptive(self) -> Dict[str, any]:\n",
    "        \"\"\"انتظار والنقر على Verified مع التعلم التكيفي\"\"\"\n",
    "        try:\n",
    "            # انتظار ظهور Verified مع التعلم\n",
    "            wait_result = self.wait_manager.smart_wait_for_element(['verified'], context='verified')\n",
    "            \n",
    "            if not wait_result['success']:\n",
    "                return {'success': False, 'error': 'verified_not_found', 'wait_result': wait_result}\n",
    "            \n",
    "            # النقر على Verified مع التعلم\n",
    "            click_success = self.click_manager.smart_click(wait_result['detection'], 'verified')\n",
    "            \n",
    "            if click_success:\n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'detection': wait_result['detection'],\n",
    "                    'wait_time': wait_result['elapsed_time'],\n",
    "                    'learning_applied': True\n",
    "                }\n",
    "            else:\n",
    "                return {'success': False, 'error': 'verified_click_failed'}\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في انتظار Verified: {e}\")\n",
    "            return {'success': False, 'error': f'exception: {str(e)}'}\n",
    "    \n",
    "    async def _wait_for_final_success_adaptive(self) -> Dict[str, any]:\n",
    "        \"\"\"انتظار النجاح النهائي مع التعلم التكيفي\"\"\"\n",
    "        try:\n",
    "            # انتظار ظهور Done أو Google مع التعلم\n",
    "            wait_result = self.wait_manager.smart_wait_for_element(['done', 'google'], context='success')\n",
    "            \n",
    "            if wait_result['success']:\n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'element': wait_result['element'],\n",
    "                    'detection': wait_result['detection'],\n",
    "                    'wait_time': wait_result['elapsed_time'],\n",
    "                    'learning_applied': True\n",
    "                }\n",
    "            else:\n",
    "                return {'success': False, 'error': 'final_success_timeout', 'wait_result': wait_result}\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في انتظار النجاح النهائي: {e}\")\n",
    "            return {'success': False, 'error': f'exception: {str(e)}'}\n",
    "    \n",
    "    def _extract_detection_region(self, image: np.ndarray, detection: Dict) -> np.ndarray:\n",
    "        \"\"\"استخراج منطقة الكشف من الصورة\"\"\"\n",
    "        try:\n",
    "            x, y = detection['location']\n",
    "            w, h = detection['template_size']\n",
    "            \n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            w = min(w, image.shape[1] - x)\n",
    "            h = min(h, image.shape[0] - y)\n",
    "            \n",
    "            return image[y:y+h, x:x+w]\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في استخراج منطقة الكشف: {e}\")\n",
    "            return image[:50, :100]\n",
    "    \n",
    "    async def _update_ml_with_success(self, cycle_result: Dict):\n",
    "        \"\"\"تحديث نماذج ML بناءً على النجاح\"\"\"\n",
    "        try:\n",
    "            if not cycle_result.get('success'):\n",
    "                return\n",
    "            \n",
    "            training_sample = {\n",
    "                'result': 'success',\n",
    "                'confidence': 0.9,\n",
    "                'duration': cycle_result['total_time'],\n",
    "                'steps': cycle_result['steps_completed'],\n",
    "                'advanced_features': {},\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'learning_applied': cycle_result.get('learning_applied', False)\n",
    "            }\n",
    "            \n",
    "            if 'features' in cycle_result:\n",
    "                training_sample['advanced_features'] = cycle_result['features']\n",
    "            \n",
    "            asyncio.create_task(self._async_model_training([training_sample]))\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في تحديث ML: {e}\")\n",
    "    \n",
    "    async def _async_model_training(self, training_samples: List[Dict]):\n",
    "        \"\"\"تدريب النماذج بشكل غير متزامن\"\"\"\n",
    "        try:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "                await loop.run_in_executor(\n",
    "                    executor, \n",
    "                    self.ml_engine.train_models, \n",
    "                    training_samples\n",
    "                )\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"خطأ في التدريب غير المتزامن: {e}\")\n",
    "    \n",
    "        def _should_auto_save_session(self) -> bool:\n",
    "          \"\"\"تحديد ما إذا كان يجب الحفظ التلقائي للجلسة\"\"\"\n",
    "        try:\n",
    "            auto_save_interval = int(self.config_manager.config.get('LEARNING', 'auto_save_interval', fallback='300'))\n",
    "            time_since_last_save = time.time() - self.current_session.get('last_auto_save', 0)\n",
    "            return time_since_last_save > auto_save_interval\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    async def run_continuous_monitoring(self):\n",
    "        \"\"\"تشغيل المراقبة المستمرة مع التعلم التكيفي\"\"\"\n",
    "        logging.info(\"🚀 بدء المراقبة المستمرة مع التعلم التكيفي المتقدم\")\n",
    "        \n",
    "        last_stats_print = time.time()\n",
    "        last_save = time.time()\n",
    "        consecutive_errors = 0\n",
    "        max_consecutive_errors = 10\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                cycle_start = time.time()\n",
    "                \n",
    "                try:\n",
    "                    # تنفيذ دورة حل مع التعلم\n",
    "                    cycle_result = await self.solve_captcha_cycle()\n",
    "                    \n",
    "                    # تحليل النتيجة\n",
    "                    if cycle_result['success']:\n",
    "                        consecutive_errors = 0\n",
    "                        self.system_state = \"operating_normally\"\n",
    "                        \n",
    "                        # تحديث معدل النجاح\n",
    "                        if 'success_rate_history' not in self.current_session:\n",
    "                            self.current_session['success_rate_history'] = []\n",
    "                        \n",
    "                        current_success_rate = self.current_session['captchas_solved'] / max(self.current_session['cycles_completed'], 1)\n",
    "                        self.current_session['success_rate_history'].append({\n",
    "                            'timestamp': time.time(),\n",
    "                            'success_rate': current_success_rate,\n",
    "                            'learning_applied': cycle_result.get('learning_applied', False)\n",
    "                        })\n",
    "                        \n",
    "                        # الاحتفاظ بآخر 100 نقطة فقط\n",
    "                        if len(self.current_session['success_rate_history']) > 100:\n",
    "                            self.current_session['success_rate_history'] = self.current_session['success_rate_history'][-100:]\n",
    "                        \n",
    "                    else:\n",
    "                        consecutive_errors += 1\n",
    "                        \n",
    "                        if consecutive_errors >= max_consecutive_errors:\n",
    "                            logging.error(f\"❌ تم الوصول للحد الأقصى من الأخطاء المتتالية: {consecutive_errors}\")\n",
    "                            self.system_state = \"error_recovery\"\n",
    "                            \n",
    "                            await self._attempt_system_recovery()\n",
    "                            consecutive_errors = 0\n",
    "                    \n",
    "                    # طباعة الإحصائيات مع معلومات التعلم\n",
    "                    if time.time() - last_stats_print > 300:  # كل 5 دقائق\n",
    "                        await self._print_comprehensive_stats_with_learning()\n",
    "                        last_stats_print = time.time()\n",
    "                    \n",
    "                    # حفظ البيانات\n",
    "                    if time.time() - last_save > 600:  # كل 10 دقائق\n",
    "                        self._save_session_data()\n",
    "                        self.learning_engine._save_learning_data()\n",
    "                        last_save = time.time()\n",
    "                        logging.info(\"💾 تم الحفظ التلقائي الشامل\")\n",
    "                    \n",
    "                    # تنظيف الذاكرة إذا لزم الأمر\n",
    "                    if self.performance_monitor.should_cleanup():\n",
    "                        self.performance_monitor.cleanup_memory()\n",
    "                        self.screenshot_manager.cleanup_cache()\n",
    "                        self.template_matcher._cleanup_cache()\n",
    "                    \n",
    "                    # تحديد سرعة الدورة التالية بناءً على التعلم\n",
    "                    cycle_duration = time.time() - cycle_start\n",
    "                    \n",
    "                    if cycle_result['success']:\n",
    "                        # دورة ناجحة، انتظار قصير مع تحسين تدريجي\n",
    "                        optimal_delay = self.learning_engine.get_optimal_click_delay()\n",
    "                        await asyncio.sleep(max(0.3, optimal_delay * 0.5))\n",
    "                    elif cycle_result.get('reason') == 'no_captcha_found':\n",
    "                        # لا توجد كابتشا، انتظار عادي\n",
    "                        await asyncio.sleep(1.0)\n",
    "                    else:\n",
    "                        # خطأ، انتظار أطول مع تعلم من الفشل\n",
    "                        failure_delay = self.learning_engine.get_optimal_click_delay() * 2\n",
    "                        await asyncio.sleep(min(5.0, failure_delay))\n",
    "                \n",
    "                except KeyboardInterrupt:\n",
    "                    logging.info(\"🛑 تم إيقاف النظام بواسطة المستخدم\")\n",
    "                    break\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logging.error(f\"❌ خطأ في دورة المراقبة: {e}\")\n",
    "                    consecutive_errors += 1\n",
    "                    \n",
    "                    if consecutive_errors >= max_consecutive_errors:\n",
    "                        logging.critical(f\"💥 خطأ حرج: {consecutive_errors} أخطاء متتالية\")\n",
    "                        await self._attempt_system_recovery()\n",
    "                        consecutive_errors = 0\n",
    "                    \n",
    "                    await asyncio.sleep(5.0)\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.critical(f\"💥 خطأ حرج في النظام: {e}\")\n",
    "            \n",
    "        finally:\n",
    "            # حفظ البيانات النهائية\n",
    "            self._save_session_data()\n",
    "            self.learning_engine._save_learning_data()\n",
    "            await self._print_final_summary_with_learning()\n",
    "            logging.info(\"🏁 تم إنهاء المراقبة المستمرة مع حفظ جميع بيانات التعلم\")\n",
    "    \n",
    "    async def _attempt_system_recovery(self):\n",
    "        \"\"\"محاولة استعادة النظام من الأخطاء\"\"\"\n",
    "        try:\n",
    "            logging.info(\"🔧 بدء محاولة استعادة النظام...\")\n",
    "            \n",
    "            # تنظيف شامل للذاكرة\n",
    "            self.performance_monitor.cleanup_memory()\n",
    "            self.screenshot_manager.cleanup_cache()\n",
    "            self.template_matcher._cleanup_cache()\n",
    "            \n",
    "            # إعادة تحميل القوالب\n",
    "            self.template_matcher._load_templates()\n",
    "            \n",
    "            # حفظ بيانات التعلم قبل الاستعادة\n",
    "            self.learning_engine._save_learning_data()\n",
    "            \n",
    "            # إعادة تعيين الحالات\n",
    "            self.system_state = \"recovering\"\n",
    "            \n",
    "            await asyncio.sleep(10.0)\n",
    "            \n",
    "            # اختبار بسيط للنظام\n",
    "            test_screenshot = self.screenshot_manager.capture_smart_screenshot(force_full=True)\n",
    "            \n",
    "            if test_screenshot is not None:\n",
    "                logging.info(\"✅ تم استعادة النظام بنجاح مع الاحتفاظ بالتعلم\")\n",
    "                self.system_state = \"operating_normally\"\n",
    "                return True\n",
    "            else:\n",
    "                logging.error(\"❌ فشل في استعادة النظام\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"❌ خطأ في استعادة النظام: {e}\")\n",
    "            return False\n",
    "    \n",
    "    async def _print_comprehensive_stats_with_learning(self):\n",
    "        \"\"\"طباعة إحصائيات شاملة مع معلومات التعلم\"\"\"\n",
    "        try:\n",
    "            session_duration = time.time() - self.current_session['start_time']\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"📊 إحصائيات النظام المتقدم مع التعلم التكيفي\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            # إحصائيات الجلسة الحالية\n",
    "            print(f\"⏰ مدة الجلسة: {session_duration/3600:.1f} ساعة\")\n",
    "            print(f\"🔄 دورات مكتملة: {self.current_session['cycles_completed']:,}\")\n",
    "            print(f\"🎯 كابتشا محلولة: {self.current_session['captchas_solved']}\")\n",
    "            print(f\"❌ أخطاء واجهت: {self.current_session['errors_encountered']}\")\n",
    "            \n",
    "            if self.current_session['cycles_completed'] > 0:\n",
    "                success_rate = self.current_session['captchas_solved'] / self.current_session['cycles_completed']\n",
    "                print(f\"📈 معدل النجاح: {success_rate:.1%}\")\n",
    "            \n",
    "            if self.current_session.get('best_solving_time', float('inf')) != float('inf'):\n",
    "                print(f\"⚡ أفضل وقت حل: {self.current_session['best_solving_time']:.2f}s\")\n",
    "            \n",
    "            # إحصائيات التعلم التكيفي\n",
    "            learning_stats = self.learning_engine.get_learning_statistics()\n",
    "            print(f\"\\n🧠 إحصائيات التعلم التكيفي:\")\n",
    "            print(f\"   📚 عينات التعلم: {learning_stats['total_samples']}\")\n",
    "            print(f\"   ✅ تكيفات ناجحة: {learning_stats['successful_adaptations']}\")\n",
    "            print(f\"   ❌ تكيفات فاشلة: {learning_stats['failed_adaptations']}\")\n",
    "            print(f\"   📊 معدل التكيف: {learning_stats['adaptation_rate']:.1%}\")\n",
    "            \n",
    "            # المعاملات المحسنة\n",
    "            current_params = learning_stats['current_parameters']\n",
    "            print(f\"\\n⚙️ المعاملات المحسنة:\")\n",
    "            print(f\"   ⏳ مهلة Verified: {current_params['verified_timeout']:.1f}s\")\n",
    "            print(f\"   🎯 مهلة النجاح: {current_params['success_timeout']:.1f}s\")\n",
    "            print(f\"   🖱️ تأخير النقر: {current_params['click_delay']:.3f}s\")\n",
    "            print(f\"   🎯 عتبة الثقة: {current_params['confidence_threshold']:.3f}\") \n",
    "            print(f\"⏰ إجمالي مدة التشغيل: {total_duration/3600:.2f} ساعة\")\n",
    "            print(f\"🔄 إجمالي الدورات: {self.current_session['cycles_completed']:,}\")\n",
    "            print(f\"🎯 إجمالي الكابتشا المحلولة: {self.current_session['captchas_solved']}\")\n",
    "            print(f\"❌ إجمالي الأخطاء: {self.current_session['errors_encountered']}\")\n",
    "            \n",
    "            if self.current_session['cycles_completed'] > 0:\n",
    "                overall_success_rate = self.current_session['captchas_solved'] / self.current_session['cycles_completed']\n",
    "                print(f\"📈 معدل النجاح الإجمالي: {overall_success_rate:.1%}\")\n",
    "                \n",
    "                avg_cycle_time = total_duration / self.current_session['cycles_completed']\n",
    "                print(f\"⚡ متوسط وقت الدورة: {avg_cycle_time:.2f}s\")\n",
    "            \n",
    "            if self.current_session.get('best_solving_time', float('inf')) != float('inf'):\n",
    "                print(f\"🏆 أفضل وقت حل: {self.current_session['best_solving_time']:.2f}s\")\n",
    "            \n",
    "            # إنجازات التعلم التكيفي\n",
    "            learning_stats = self.learning_engine.get_learning_statistics()\n",
    "            print(f\"\\n🧠 إنجازات التعلم التكيفي:\")\n",
    "            print(f\"   📚 إجمالي عينات التعلم: {learning_stats['total_samples']}\")\n",
    "            print(f\"   ✅ تكيفات ناجحة: {learning_stats['successful_adaptations']}\")\n",
    "            print(f\"   📊 معدل التكيف النهائي: {learning_stats['adaptation_rate']:.1%}\")\n",
    "            \n",
    "            # تحسينات الأداء المكتسبة\n",
    "            current_params = learning_stats['current_parameters']\n",
    "            print(f\"\\n⚡ تحسينات الأداء المكتسبة:\")\n",
    "            print(f\"   ⏳ مهلة Verified محسنة: {current_params['verified_timeout']:.1f}s\")\n",
    "            print(f\"   🎯 مهلة النجاح محسنة: {current_params['success_timeout']:.1f}s\")\n",
    "            print(f\"   🖱️ تأخير النقر محسن: {current_params['click_delay']:.3f}s\")\n",
    "            print(f\"   🎯 عتبة الثقة محسنة: {current_params['confidence_threshold']:.3f}\")\n",
    "            \n",
    "            # إحصائيات التعلم الآلي\n",
    "            if self.ml_engine.is_trained:\n",
    "                print(f\"\\n🤖 إنجازات التعلم الآلي:\")\n",
    "                print(f\"   📚 عينات مدربة: {self.ml_engine.model_stats['training_samples']}\")\n",
    "                print(f\"   🎯 نماذج مدربة: {len([m for m in self.ml_engine.models.values() if m is not None])}\")\n",
    "                \n",
    "                if 'accuracy_scores' in self.ml_engine.model_stats:\n",
    "                    avg_accuracy = np.mean(list(self.ml_engine.model_stats['accuracy_scores'].values()))\n",
    "                    print(f\"   📊 متوسط دقة النماذج: {avg_accuracy:.1%}\")\n",
    "                \n",
    "                if HAS_STATSMODELS:\n",
    "                    print(f\"   📈 إحصائيات متقدمة مع statsmodels: متاحة\")\n",
    "            \n",
    "            # تحليل تطور الأداء\n",
    "            if 'success_rate_history' in self.current_session and len(self.current_session['success_rate_history']) > 5:\n",
    "                history = self.current_session['success_rate_history']\n",
    "                initial_rate = np.mean([h['success_rate'] for h in history[:5]])\n",
    "                final_rate = np.mean([h['success_rate'] for h in history[-5:]])\n",
    "                improvement = final_rate - initial_rate\n",
    "                \n",
    "                print(f\"\\n📈 تطور الأداء:\")\n",
    "                print(f\"   📊 معدل النجاح الأولي: {initial_rate:.1%}\")\n",
    "                print(f\"   📊 معدل النجاح النهائي: {final_rate:.1%}\")\n",
    "                print(f\"   {'📈' if improvement > 0 else '📉'} التحسن: {improvement:+.1%}\")\n",
    "            \n",
    "            # توصيات مخصصة بناءً على التعلم\n",
    "            print(f\"\\n💡 توصيات مخصصة بناءً على التعلم:\")\n",
    "            \n",
    "            if learning_stats['adaptation_rate'] > 0.8:\n",
    "                print(\"   🎯 النظام يتعلم بكفاءة عالية - استمر في التشغيل\")\n",
    "            elif learning_stats['adaptation_rate'] < 0.5:\n",
    "                print(\"   📚 النظام يحتاج المزيد من البيانات للتعلم الأمثل\")\n",
    "            \n",
    "            if overall_success_rate > 0.9:\n",
    "                print(\"   ⚡ أداء ممتاز - يمكن تقليل أوقات الانتظار أكثر\")\n",
    "            elif overall_success_rate < 0.7:\n",
    "                print(\"   🔧 يُنصح بزيادة أوقات الانتظار للحصول على استقرار أكثر\")\n",
    "            \n",
    "            if self.ml_engine.is_trained:\n",
    "                print(\"   🤖 نماذج ML مدربة - ستحصل على تنبؤات أفضل\")\n",
    "            else:\n",
    "                print(\"   📊 جمع المزيد من البيانات سيحسن دقة التنبؤات\")\n",
    "            \n",
    "            # معلومات الحفظ والاستئناف\n",
    "            print(f\"\\n💾 معلومات الحفظ:\")\n",
    "            print(f\"   📁 بيانات الجلسة: محفوظة\")\n",
    "            print(f\"   🧠 بيانات التعلم التكيفي: محفوظة\")\n",
    "            print(f\"   🤖 نماذج ML: محفوظة\")\n",
    "            print(f\"   📊 إحصائيات الأداء: محفوظة\")\n",
    "            \n",
    "            print(f\"\\n🔄 استئناف التشغيل:\")\n",
    "            print(f\"   ✅ يمكن استئناف التشغيل مع الاحتفاظ بجميع التحسينات\")\n",
    "            print(f\"   🧠 سيتم تطبيق جميع المعاملات المحسنة تلقائياً\")\n",
    "            print(f\"   📈 الأداء سيكون أفضل من البداية بفضل التعلم المكتسب\")\n",
    "            \n",
    "            print(f\"\\n📊 ملفات النظام:\")\n",
    "            memory_dir = self.config_manager.get_secure_path('PATHS', 'memory_dir', '')\n",
    "            print(f\"   💾 مجلد البيانات: {memory_dir}\")\n",
    "            print(f\"   🔧 ملف الإعدادات: {self.config_manager.config_path}\")\n",
    "            \n",
    "            print(\"🏁\" + \"=\"*78 + \"🏁\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في طباعة الملخص النهائي: {e}\")\n",
    "    \n",
    "    def export_comprehensive_report_with_learning(self) -> str:\n",
    "        \"\"\"تصدير تقرير شامل مع معلومات التعلم\"\"\"\n",
    "        try:\n",
    "            report_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            report_file = self.config_manager.get_secure_path(\n",
    "                'PATHS', 'memory_dir', f'comprehensive_report_with_learning_{report_timestamp}.json'\n",
    "            )\n",
    "            \n",
    "            # جمع جميع الإحصائيات مع التعلم\n",
    "            learning_stats = self.learning_engine.get_learning_statistics()\n",
    "            \n",
    "            report_data = {\n",
    "                'report_metadata': {\n",
    "                    'generated_at': datetime.now().isoformat(),\n",
    "                    'system_version': 'AdvancedCaptchaSolver_v4.0_with_Adaptive_Learning',\n",
    "                    'report_type': 'comprehensive_system_analysis_with_learning',\n",
    "                    'statsmodels_available': HAS_STATSMODELS\n",
    "                },\n",
    "                'session_summary': self.current_session.copy(),\n",
    "                'adaptive_learning_stats': learning_stats,\n",
    "                'performance_metrics': self.performance_monitor.check_resources(),\n",
    "                'ml_statistics': self.ml_engine.model_stats.copy() if self.ml_engine.is_trained else {},\n",
    "                'click_analytics': self.click_manager.get_click_statistics(),\n",
    "                'wait_analytics': self.wait_manager.get_wait_statistics(),\n",
    "                'system_configuration': {\n",
    "                    'security_config': asdict(self.security_config),\n",
    "                    'performance_config': asdict(self.performance_config),\n",
    "                    'learning_config': asdict(self.learning_config),\n",
    "                    'solving_strategy': self.solving_strategy,\n",
    "                    'max_retry_attempts': self.max_retry_attempts\n",
    "                },\n",
    "                'learned_optimizations': {\n",
    "                    'optimal_timeouts': {\n",
    "                        'verified': learning_stats['current_parameters']['verified_timeout'],\n",
    "                        'success': learning_stats['current_parameters']['success_timeout']\n",
    "                    },\n",
    "                    'optimal_delays': {\n",
    "                        'click_delay': learning_stats['current_parameters']['click_delay']\n",
    "                    },\n",
    "                    'optimal_thresholds': {\n",
    "                        'confidence_threshold': learning_stats['current_parameters']['confidence_threshold']\n",
    "                    }\n",
    "                },\n",
    "                'recommendations': self._generate_system_recommendations_with_learning()\n",
    "            }\n",
    "            \n",
    "            # حفظ التقرير\n",
    "            with open(report_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(report_data, f, indent=2, ensure_ascii=False, default=str)\n",
    "            \n",
    "            logging.info(f\"📊 تم تصدير التقرير الشامل مع التعلم إلى: {report_file}\")\n",
    "            return str(report_file)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في تصدير التقرير: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def _generate_system_recommendations_with_learning(self) -> List[str]:\n",
    "        \"\"\"توليد توصيات تحسين النظام مع التعلم\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        try:\n",
    "            # تحليل معدل النجاح\n",
    "            if self.current_session['cycles_completed'] > 0:\n",
    "                success_rate = self.current_session['captchas_solved'] / self.current_session['cycles_completed']\n",
    "                \n",
    "                if success_rate < 0.5:\n",
    "                    recommendations.append(\"معدل النجاح منخفض - النظام يتعلم، استمر في التشغيل لتحسين الأداء\")\n",
    "                elif success_rate > 0.9:\n",
    "                    recommendations.append(\"معدل نجاح ممتاز مع التعلم التكيفي - النظام محسن بشكل مثالي\")\n",
    "            \n",
    "            # تحليل التعلم التكيفي\n",
    "            learning_stats = self.learning_engine.get_learning_statistics()\n",
    "            \n",
    "            if learning_stats['adaptation_rate'] > 0.8:\n",
    "                recommendations.append(\"معدل تكيف ممتاز - النظام يتعلم بكفاءة عالية\")\n",
    "            elif learning_stats['adaptation_rate'] < 0.5:\n",
    "                recommendations.append(\"معدل تكيف منخفض - النظام يحتاج المزيد من الوقت للتعلم\")\n",
    "            \n",
    "            if learning_stats['total_samples'] < 50:\n",
    "                recommendations.append(\"عدد عينات التعلم قليل - استمر في التشغيل لجمع المزيد من البيانات\")\n",
    "            elif learning_stats['total_samples'] > 500:\n",
    "                recommendations.append(\"قاعدة بيانات تعلم ممتازة - النظام قادر على التنبؤ بدقة عالية\")\n",
    "            \n",
    "            # تحليل الأداء\n",
    "            resources = self.performance_monitor.check_resources()\n",
    "            if not resources['memory_ok']:\n",
    "                recommendations.append(\"استخدام الذاكرة مرتفع - قم بتقليل حجم البافر أو تفعيل التنظيف التلقائي\")\n",
    "            \n",
    "            # تحليل ML\n",
    "            if not self.ml_engine.is_trained:\n",
    "                recommendations.append(\"نماذج ML غير مدربة - التعلم التكيفي سيحسن الأداء تدريجياً\")\n",
    "            elif self.ml_engine.model_stats.get('training_samples', 0) > 100:\n",
    "                recommendations.append(\"نماذج ML مدربة جيداً - ستحصل على تنبؤات دقيقة\")\n",
    "            \n",
    "            # تحليل تطور الأداء\n",
    "            if 'success_rate_history' in self.current_session and len(self.current_session['success_rate_history']) > 5:\n",
    "                history = self.current_session['success_rate_history']\n",
    "                recent_improvement = history[-1]['success_rate'] - history[-5]['success_rate']\n",
    "                \n",
    "                if recent_improvement > 0.1:\n",
    "                    recommendations.append(\"الأداء يتحسن بسرعة بفضل التعلم التكيفي\")\n",
    "                elif recent_improvement < -0.1:\n",
    "                    recommendations.append(\"تراجع في الأداء - قد تحتاج لمراجعة الإعدادات\")\n",
    "            \n",
    "            # توصيات خاصة بـ statsmodels\n",
    "            if HAS_STATSMODELS:\n",
    "                recommendations.append(\"statsmodels متاحة - ستحصل على إحصائيات متقدمة وفترات ثقة دقيقة\")\n",
    "            else:\n",
    "                recommendations.append(\"تثبيت statsmodels سيوفر إحصائيات أكثر تقدماً\")\n",
    "            \n",
    "            # توصيات عامة\n",
    "            if len(recommendations) == 0:\n",
    "                recommendations.append(\"النظام يعمل بكفاءة عالية مع التعلم التكيفي المتقدم!\")\n",
    "            \n",
    "            return recommendations\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"خطأ في توليد التوصيات: {e}\")\n",
    "            return [\"خطأ في تحليل النظام - راجع السجلات للتفاصيل\"]\n",
    "\n",
    "# ================================\n",
    "# Main Execution\n",
    "# ================================\n",
    "\n",
    "async def main():\n",
    "    \"\"\"الدالة الرئيسية للتشغيل مع التعلم التكيفي\"\"\"\n",
    "    print(\"🚀\" + \"=\"*78 + \"🚀\")\n",
    "    print(\"🤖 نظام حل الكابتشا المتقدم مع التعلم التكيفي - الإصدار 4.0\")\n",
    "    print(\"🚀\" + \"=\"*78 + \"🚀\")\n",
    "    print()\n",
    "    print(\"✨ المميزات المتقدمة مع التعلم التكيفي:\")\n",
    "    print(\"   🧠 تعلم آلي متقدم مع Random Forest و Neural Networks\")\n",
    "    print(\"   🎯 تعلم تكيفي للأوقات المثلى والمعاملات\")\n",
    "    print(\"   🖱️ نقر ذكي مع تعلم الأنماط الناجحة\")\n",
    "    print(\"   ⏳ انتظار تكيفي مع تحسين مستمر للسرعة\")\n",
    "    print(\"   🔒 طبقات أمان متعددة مع تشفير البيانات\")\n",
    "    print(\"   ⚡ إدارة ذاكرة ذكية مع تنظيف تلقائي\")\n",
    "    print(\"   🎯 كشف متقدم مع مقاومة التغييرات\")\n",
    "    print(\"   📊 مراقبة أداء شاملة مع إحصائيات مفصلة\")\n",
    "    print(\"   🔄 إعادة محاولة ذكية مع استعادة تلقائية\")\n",
    "    print(\"   💾 حفظ تلقائي مع استئناف التعلم\")\n",
    "    print(\"   📈 تتبع تطور الأداء والتحسين المستمر\")\n",
    "    print(\"   🛡️ معالجة شاملة للاستثناءات\")\n",
    "    \n",
    "    if HAS_STATSMODELS:\n",
    "        print(\"   📊 إحصائيات متقدمة مع statsmodels\")\n",
    "    else:\n",
    "        print(\"   ⚠️ statsmodels غير مثبتة - سيتم استخدام إحصائيات بسيطة\")\n",
    "    \n",
    "    print()\n",
    "    print(\"🔧 إعدادات النظام المحسنة:\")\n",
    "    print(\"   📁 الملفات: config/, templates/, logs/, captcha_memory/\")\n",
    "    print(\"   🔐 الأمان: تشفير البيانات + مسارات آمنة\")\n",
    "    print(\"   💾 الذاكرة: تنظيف تلقائي + مراقبة الاستخدام\")\n",
    "    print(\"   🚀 الأداء: معالجة متوازية + كاش ذكي\")\n",
    "    print(\"   🧠 التعلم: حفظ تلقائي كل 5 دقائق\")\n",
    "    print()\n",
    "    print(\"⚠️ متطلبات التشغيل:\")\n",
    "    print(\"   • Python 3.8+ مع المكتبات المطلوبة\")\n",
    "    print(\"   • ملفات القوالب في مجلد templates/\")\n",
    "    print(\"   • صلاحيات الوصول للشاشة والماوس\")\n",
    "    print(\"   • مساحة كافية لحفظ البيانات والتعلم\")\n",
    "    print(\"   • اتصال إنترنت لتحديث المكتبات (اختياري)\")\n",
    "    print()\n",
    "    print(\"🎮 التحكم:\")\n",
    "    print(\"   • Ctrl+C للإيقاف الآمن مع حفظ التعلم\")\n",
    "    print(\"   • سيتم حفظ جميع البيانات والتحسينات تلقائياً\")\n",
    "    print(\"   • يمكن استئناف التشغيل مع الاستفادة من التعلم السابق\")\n",
    "    print(\"   • النظام سيتحسن تلقائياً مع كل استخدام\")\n",
    "    print()\n",
    "    print(\"🚀\" + \"=\"*78 + \"🚀\")\n",
    "    \n",
    "    try:\n",
    "        # إنشاء النظام المتقدم مع التعلم\n",
    "        solver = AdvancedCaptchaSolver()\n",
    "        \n",
    "        # عرض حالة النظام\n",
    "        print(\"\\n📋 حالة النظام:\")\n",
    "        print(f\"   🤖 نماذج ML: {'✅ مدربة' if solver.ml_engine.is_trained else '❌ غير مدربة'}\")\n",
    "        print(f\"   🖼️ القوالب: {len(solver.template_matcher.templates)} قالب محمل\")\n",
    "        print(f\"   🧠 التعلم التكيفي: ✅ نشط\")\n",
    "        print(f\"   🔧 الحالة: {solver.system_state}\")\n",
    "        \n",
    "        # عرض المعاملات المحسنة\n",
    "        learning_stats = solver.learning_engine.get_learning_statistics()\n",
    "        if learning_stats['total_samples'] > 0:\n",
    "            print(f\"   📚 عينات التعلم: {learning_stats['total_samples']}\")\n",
    "            print(f\"   📊 معدل التكيف: {learning_stats['adaptation_rate']:.1%}\")\n",
    "            \n",
    "            current_params = learning_stats['current_parameters']\n",
    "            print(f\"   ⏳ مهلة Verified محسنة: {current_params['verified_timeout']:.1f}s\")\n",
    "            print(f\"   🎯 مهلة النجاح محسنة: {current_params['success_timeout']:.1f}s\")\n",
    "            print(f\"   🖱️ تأخير النقر محسن: {current_params['click_delay']:.3f}s\")\n",
    "        else:\n",
    "            print(f\"   📚 عينات التعلم: 0 (سيبدأ التعلم مع الاستخدام)\")\n",
    "        \n",
    "        # فحص الموارد\n",
    "        resources = solver.performance_monitor.check_resources()\n",
    "        print(f\"   🧠 الذاكرة: {resources['memory_mb']:.1f}MB\")\n",
    "        print(f\"   ⚙️ المعالج: {resources['cpu_percent']:.1f}%\")\n",
    "        \n",
    "        # فحص statsmodels\n",
    "        if HAS_STATSMODELS:\n",
    "            print(f\"   📊 statsmodels: ✅ متاحة للإحصائيات المتقدمة\")\n",
    "        else:\n",
    "            print(f\"   📊 statsmodels: ❌ غير متاحة\")\n",
    "        \n",
    "        print(\"\\n🚀 بدء المراقبة المستمرة مع التعلم التكيفي...\")\n",
    "        print(\"💡 النظام سيتعلم ويتحسن تلقائياً مع كل استخدام\")\n",
    "        print(\"📊 ستظهر الإحصائيات مع معلومات التعلم كل 5 دقائق\")\n",
    "        print(\"💾 سيتم الحفظ التلقائي للتعلم كل 5 دقائق\")\n",
    "        print(\"🎯 الأداء سيتحسن تدريجياً مع جمع المزيد من البيانات\")\n",
    "        print(\"⚡ أوقات الانتظار والنقر ستصبح أكثر دقة مع التعلم\")\n",
    "        print()\n",
    "        \n",
    "        # بدء المراقبة المستمرة مع التعلم\n",
    "        await solver.run_continuous_monitoring()\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n🛑 تم إيقاف النظام بواسطة المستخدم\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n💥 خطأ حرج في النظام: {e}\")\n",
    "        logging.critical(f\"خطأ حرج في main: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        try:\n",
    "            # تصدير تقرير نهائي مع التعلم\n",
    "            if 'solver' in locals():\n",
    "                report_file = solver.export_comprehensive_report_with_learning()\n",
    "                if report_file:\n",
    "                    print(f\"📊 تم تصدير التقرير النهائي مع التعلم: {report_file}\")\n",
    "                \n",
    "                print(\"\\n💾 تم حفظ جميع البيانات والتعلم المكتسب:\")\n",
    "                print(\"   🧠 بيانات التعلم التكيفي\")\n",
    "                print(\"   🤖 نماذج التعلم الآلي\")\n",
    "                print(\"   📊 إحصائيات الأداء\")\n",
    "                print(\"   ⚙️ المعاملات المحسنة\")\n",
    "                print(\"   📈 تاريخ التحسينات\")\n",
    "                \n",
    "                print(\"\\n🔄 عند إعادة التشغيل:\")\n",
    "                print(\"   ✅ سيتم تطبيق جميع التحسينات المكتسبة\")\n",
    "                print(\"   ⚡ الأداء سيكون أفضل من البداية\")\n",
    "                print(\"   🧠 التعلم سيستمر من حيث توقف\")\n",
    "                print(\"   📈 معدل النجاح سيكون أعلى\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ خطأ في الحفظ النهائي: {e}\")\n",
    "        \n",
    "        print(\"\\n🏁 تم إنهاء النظام بأمان مع حفظ جميع التحسينات\")\n",
    "\n",
    "# ================================\n",
    "# Entry Point\n",
    "# ================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # فحص المتطلبات الأساسية\n",
    "        required_modules = [\n",
    "            'mss', 'cv2', 'numpy', 'pyautogui', 'sklearn', \n",
    "            'skimage', 'scipy', 'cryptography', 'psutil'\n",
    "        ]\n",
    "        \n",
    "        missing_modules = []\n",
    "        for module in required_modules:\n",
    "            try:\n",
    "                __import__(module)\n",
    "            except ImportError:\n",
    "                missing_modules.append(module)\n",
    "        \n",
    "        if missing_modules:\n",
    "            print(\"❌ مكتبات مفقودة:\")\n",
    "            for module in missing_modules:\n",
    "                print(f\"   • {module}\")\n",
    "            print(\"\\n📦 قم بتثبيت المكتبات المفقودة:\")\n",
    "            print(\"pip install mss opencv-python numpy pyautogui scikit-learn\")\n",
    "            print(\"pip install scikit-image scipy cryptography psutil\")\n",
    "            print(\"pip install statsmodels  # للإحصائيات المتقدمة\")\n",
    "            exit(1)\n",
    "        \n",
    "        # فحص إصدار Python\n",
    "        import sys\n",
    "        if sys.version_info < (3, 8):\n",
    "            print(\"❌ يتطلب Python 3.8 أو أحدث\")\n",
    "            exit(1)\n",
    "        \n",
    "        # إنشاء المجلدات المطلوبة\n",
    "        required_dirs = ['config', 'templates', 'logs', 'captcha_memory', 'temp']\n",
    "        for dir_name in required_dirs:\n",
    "            Path(dir_name).mkdir(exist_ok=True)\n",
    "        \n",
    "        # فحص ملفات القوالب\n",
    "        template_files = ['recaptcha.png', 'verified.png', 'done.png', 'google.png']\n",
    "        missing_templates = []\n",
    "        \n",
    "        for template in template_files:\n",
    "            template_path = Path('templates') / template\n",
    "            if not template_path.exists():\n",
    "                missing_templates.append(template)\n",
    "        \n",
    "        if missing_templates:\n",
    "            print(\"⚠️ ملفات قوالب مفقودة:\")\n",
    "            for template in missing_templates:\n",
    "                print(f\"   • templates/{template}\")\n",
    "            print(\"\\n💡 سيتم إنشاء قوالب احتياطية تلقائياً\")\n",
    "            print(\"🔧 للحصول على أفضل أداء، ضع ملفات القوالب الصحيحة في مجلد templates/\")\n",
    "        \n",
    "        # فحص statsmodels\n",
    "        try:\n",
    "            import statsmodels\n",
    "            print(\"✅ statsmodels متاحة - ستحصل على إحصائيات متقدمة\")\n",
    "        except ImportError:\n",
    "            print(\"⚠️ statsmodels غير مثبتة - سيتم استخدام إحصائيات بسيطة\")\n",
    "            print(\"💡 لتثبيت statsmodels: pip install statsmodels\")\n",
    "        \n",
    "        # تشغيل النظام\n",
    "        asyncio.run(main())\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n🛑 تم إلغاء التشغيل\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n💥 خطأ في بدء التشغيل: {e}\")\n",
    "        logging.critical(f\"خطأ في بدء التشغيل: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        print(\"\\n👋 شكراً لاستخدام نظام حل الكابتشا المتقدم مع التعلم التكيفي!\")\n",
    "        print(\"🧠 كلما استخدمته أكثر، كلما أصبح أذكى وأسرع!\")\n",
    "        print(\"💾 جميع التحسينات محفوظة للاستخدام القادم\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce60b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
